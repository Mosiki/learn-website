<!DOCTYPE html>
<!-- saved from url=(0046)https://kaiiiz.github.io/hexo-theme-book-demo/ -->
<html xmlns="http://www.w3.org/1999/xhtml">

<head>

    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
        <link rel="icon" href="../../static/favicon.png">
        <title>097 LDA模型的前世今生.md</title>
        <!-- Spectre.css framework -->
        <link rel="stylesheet" href="../../static/index.css">
        <link rel="stylesheet"
              href="../../static/highlight.min.css">
        <script src="../../static/highlight.min.js"></script>
        <!-- theme css & js -->
        <meta name="generator" content="Hexo 4.2.0">
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5295275829820252"
                crossorigin="anonymous"></script>
        <script async defer data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" src="https://analyze.lianglianglee.com/umami.js"></script>
    </head>

<body>

    <div class="book-container">
        <div class="book-sidebar">
            <div class="book-brand">
                <a href="../../index.html">
                    <img src="../../static/favicon.png">
                    <span>技术文章摘抄</span>
                </a>
            </div>
            <div class="book-menu uncollapsible">
                <ul class="uncollapsible">
                    <li><a href="../../index.html" class="current-tab">首页</a></li>
                </ul>

                <ul class="uncollapsible">
                    <li><a href="../index.html">上一级</a></li>
                </ul>

                <ul class="uncollapsible">
                    <li>

                        
                        <a href="000%20%E5%BC%80%E7%AF%87%E8%AF%8D%20%E4%BD%A0%E7%9A%84360%E5%BA%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BF%A1%E6%81%AF%E5%8A%A9%E7%90%86.md.html">000 开篇词 你的360度人工智能信息助理.md</a>

                    </li>
                    <li>

                        
                        <a href="001%20%E8%81%8A%E8%81%8A2017%E5%B9%B4KDD%E5%A4%A7%E4%BC%9A%E7%9A%84%E6%97%B6%E9%97%B4%E6%A3%80%E9%AA%8C%E5%A5%96.md.html">001 聊聊2017年KDD大会的时间检验奖.md</a>

                    </li>
                    <li>

                        
                        <a href="002%20%E7%B2%BE%E8%AF%BB2017%E5%B9%B4KDD%E6%9C%80%E4%BD%B3%E7%A0%94%E7%A9%B6%E8%AE%BA%E6%96%87.md.html">002 精读2017年KDD最佳研究论文.md</a>

                    </li>
                    <li>

                        
                        <a href="003%20%E7%B2%BE%E8%AF%BB2017%E5%B9%B4KDD%E6%9C%80%E4%BD%B3%E5%BA%94%E7%94%A8%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E8%AE%BA%E6%96%87.md.html">003 精读2017年KDD最佳应用数据科学论文.md</a>

                    </li>
                    <li>

                        
                        <a href="004%20%E7%B2%BE%E8%AF%BB2017%E5%B9%B4EMNLP%E6%9C%80%E4%BD%B3%E9%95%BF%E8%AE%BA%E6%96%87%E4%B9%8B%E4%B8%80.md.html">004 精读2017年EMNLP最佳长论文之一.md</a>

                    </li>
                    <li>

                        
                        <a href="005%20%E7%B2%BE%E8%AF%BB2017%E5%B9%B4EMNLP%E6%9C%80%E4%BD%B3%E9%95%BF%E8%AE%BA%E6%96%87%E4%B9%8B%E4%BA%8C.md.html">005 精读2017年EMNLP最佳长论文之二.md</a>

                    </li>
                    <li>

                        
                        <a href="006%20%E7%B2%BE%E8%AF%BB2017%E5%B9%B4EMNLP%E6%9C%80%E4%BD%B3%E7%9F%AD%E8%AE%BA%E6%96%87.md.html">006 精读2017年EMNLP最佳短论文.md</a>

                    </li>
                    <li>

                        
                        <a href="007%20%E7%B2%BE%E8%AF%BB2017%E5%B9%B4ICCV%E6%9C%80%E4%BD%B3%E7%A0%94%E7%A9%B6%E8%AE%BA%E6%96%87.md.html">007 精读2017年ICCV最佳研究论文.md</a>

                    </li>
                    <li>

                        
                        <a href="008%20%E7%B2%BE%E8%AF%BB2017%E5%B9%B4ICCV%E6%9C%80%E4%BD%B3%E5%AD%A6%E7%94%9F%E8%AE%BA%E6%96%87.md.html">008 精读2017年ICCV最佳学生论文.md</a>

                    </li>
                    <li>

                        
                        <a href="009%20%E5%A6%82%E4%BD%95%E5%B0%86%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8%E5%88%B0%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%EF%BC%9F.md.html">009 如何将深度强化学习应用到视觉问答系统？.md</a>

                    </li>
                    <li>

                        
                        <a href="010%20%E7%B2%BE%E8%AF%BB2017%E5%B9%B4NIPS%E6%9C%80%E4%BD%B3%E7%A0%94%E7%A9%B6%E8%AE%BA%E6%96%87%E4%B9%8B%E4%B8%80%EF%BC%9A%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E9%9D%9E%E5%87%B8%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%EF%BC%9F.md.html">010 精读2017年NIPS最佳研究论文之一：如何解决非凸优化问题？.md</a>

                    </li>
                    <li>

                        
                        <a href="011%20%E7%B2%BE%E8%AF%BB2017%E5%B9%B4NIPS%E6%9C%80%E4%BD%B3%E7%A0%94%E7%A9%B6%E8%AE%BA%E6%96%87%E4%B9%8B%E4%BA%8C%EF%BC%9AKSD%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E6%A3%80%E9%AA%8C%E4%B8%A4%E4%B8%AA%E5%88%86%E5%B8%83%E7%9A%84%E5%BC%82%E5%90%8C%EF%BC%9F.md.html">011 精读2017年NIPS最佳研究论文之二：KSD测试如何检验两个分布的异同？.md</a>

                    </li>
                    <li>

                        
                        <a href="012%20%E7%B2%BE%E8%AF%BB2017%E5%B9%B4NIPS%E6%9C%80%E4%BD%B3%E7%A0%94%E7%A9%B6%E8%AE%BA%E6%96%87%E4%B9%8B%E4%B8%89%EF%BC%9A%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E9%9D%9E%E5%AE%8C%E7%BE%8E%E4%BF%A1%E6%81%AF%E5%8D%9A%E5%BC%88%E9%97%AE%E9%A2%98%EF%BC%9F.md.html">012 精读2017年NIPS最佳研究论文之三：如何解决非完美信息博弈问题？.md</a>

                    </li>
                    <li>

                        
                        <a href="013%20WSDM%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E7%9C%8B%E8%B0%B7%E6%AD%8C%E5%9B%A2%E9%98%9F%E5%A6%82%E4%BD%95%E5%81%9A%E4%BD%8D%E7%BD%AE%E5%81%8F%E5%B7%AE%E4%BC%B0%E8%AE%A1.md.html">013 WSDM 2018论文精读：看谷歌团队如何做位置偏差估计.md</a>

                    </li>
                    <li>

                        
                        <a href="014%20WSDM%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E7%9C%8B%E4%BA%AC%E4%B8%9C%E5%9B%A2%E9%98%9F%E5%A6%82%E4%BD%95%E6%8C%96%E6%8E%98%E5%95%86%E5%93%81%E7%9A%84%E6%9B%BF%E4%BB%A3%E4%BF%A1%E6%81%AF%E5%92%8C%E4%BA%92%E8%A1%A5%E4%BF%A1%E6%81%AF.md.html">014 WSDM 2018论文精读：看京东团队如何挖掘商品的替代信息和互补信息.md</a>

                    </li>
                    <li>

                        
                        <a href="015%20WSDM%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B8%AD%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF%EF%BC%9F.md.html">015 WSDM 2018论文精读：深度学习模型中如何使用上下文信息？.md</a>

                    </li>
                    <li>

                        
                        <a href="016%20The%20Web%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E5%AF%B9%E5%95%86%E5%93%81%E7%9A%84%E5%9B%BE%E7%89%87%E7%BE%8E%E6%84%9F%E8%BF%9B%E8%A1%8C%E5%BB%BA%E6%A8%A1%EF%BC%9F.md.html">016 The Web 2018论文精读：如何对商品的图片美感进行建模？.md</a>

                    </li>
                    <li>

                        
                        <a href="017%20The%20Web%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E6%94%B9%E8%BF%9B%E7%BB%8F%E5%85%B8%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95BPR%EF%BC%9F.md.html">017 The Web 2018论文精读：如何改进经典的推荐算法BPR？.md</a>

                    </li>
                    <li>

                        
                        <a href="018%20The%20Web%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BB%8E%E6%96%87%E6%9C%AC%E4%B8%AD%E6%8F%90%E5%8F%96%E9%AB%98%E5%85%83%E5%85%B3%E7%B3%BB%EF%BC%9F.md.html">018 The Web 2018论文精读：如何从文本中提取高元关系？.md</a>

                    </li>
                    <li>

                        
                        <a href="019%20SIGIR%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%81%8F%E5%B7%AE%E5%92%8C%E6%B5%81%E8%A1%8C%E5%BA%A6%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.md.html">019 SIGIR 2018论文精读：偏差和流行度之间的关系.md</a>

                    </li>
                    <li>

                        
                        <a href="020%20SIGIR%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E5%AF%B9%E6%8A%97%E5%AD%A6%E4%B9%A0%E6%9D%A5%E5%A2%9E%E5%BC%BA%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%AE%E9%80%82%E6%80%A7%EF%BC%9F.md.html">020 SIGIR 2018论文精读：如何利用对抗学习来增强排序模型的普适性？.md</a>

                    </li>
                    <li>

                        
                        <a href="021%20SIGIR%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E5%AF%B9%E6%90%9C%E7%B4%A2%E9%A1%B5%E9%9D%A2%E4%B8%8A%E7%9A%84%E7%82%B9%E5%87%BB%E8%A1%8C%E4%B8%BA%E8%BF%9B%E8%A1%8C%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1%EF%BC%9F.md.html">021 SIGIR 2018论文精读：如何对搜索页面上的点击行为进行序列建模？.md</a>

                    </li>
                    <li>

                        
                        <a href="022%20CVPR%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E7%A0%94%E7%A9%B6%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%BB%E5%8A%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%EF%BC%9F.md.html">022 CVPR 2018论文精读：如何研究计算机视觉任务之间的关系？.md</a>

                    </li>
                    <li>

                        
                        <a href="023%20CVPR%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BB%8E%E6%95%B4%E4%BD%93%E4%B8%8A%E5%AF%B9%E4%BA%BA%E4%BD%93%E8%BF%9B%E8%A1%8C%E4%B8%89%E7%BB%B4%E5%BB%BA%E6%A8%A1%EF%BC%9F.md.html">023 CVPR 2018论文精读：如何从整体上对人体进行三维建模？.md</a>

                    </li>
                    <li>

                        
                        <a href="024%20CVPR%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%8E%92%E5%BA%8F%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E9%AB%98%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%9F.md.html">024 CVPR 2018论文精读：如何解决排序学习计算复杂度高这个问题？.md</a>

                    </li>
                    <li>

                        
                        <a href="025%20ICML%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E6%A8%A1%E5%9E%8B%E7%BB%8F%E5%BE%97%E8%B5%B7%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%9A%84%E6%94%BB%E5%87%BB%EF%BC%9F%E8%BF%99%E6%88%96%E8%AE%B8%E5%8F%AA%E6%98%AF%E4%B8%AA%E9%94%99%E8%A7%89.md.html">025 ICML 2018论文精读：模型经得起对抗样本的攻击？这或许只是个错觉.md</a>

                    </li>
                    <li>

                        
                        <a href="026%20ICML%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E8%81%8A%E4%B8%80%E8%81%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E5%85%AC%E5%B9%B3%E6%80%A7%E9%97%AE%E9%A2%98.md.html">026 ICML 2018论文精读：聊一聊机器学习算法的公平性问题.md</a>

                    </li>
                    <li>

                        
                        <a href="027%20ICML%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E6%9C%89%E5%8F%AF%E8%83%BD%E6%94%BE%E5%A4%A7%E4%BA%86%E4%B8%8D%E5%85%AC%E5%B9%B3%EF%BC%9F.md.html">027 ICML 2018论文精读：优化目标函数的时候，有可能放大了不公平？.md</a>

                    </li>
                    <li>

                        
                        <a href="028%20ACL%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E5%9C%BA%E6%99%AF%E4%B8%8B%EF%BC%8C%E5%A6%82%E4%BD%95%E6%8F%90%E5%87%BA%E5%A5%BD%E9%97%AE%E9%A2%98%EF%BC%9F.md.html">028 ACL 2018论文精读：问答系统场景下，如何提出好问题？.md</a>

                    </li>
                    <li>

                        
                        <a href="029%20ACL%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E5%AF%B9%E8%AF%9D%E4%B8%AD%E7%9A%84%E5%89%8D%E6%8F%90%E8%A7%A6%E5%8F%91%EF%BC%9F%E5%A6%82%E4%BD%95%E6%A3%80%E6%B5%8B%EF%BC%9F.md.html">029 ACL 2018论文精读：什么是对话中的前提触发？如何检测？.md</a>

                    </li>
                    <li>

                        
                        <a href="030%20ACL%202018%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E8%AF%AD%E4%B9%89%E5%93%88%E5%B8%8C%EF%BC%9F.md.html">030 ACL 2018论文精读：什么是端到端的语义哈希？.md</a>

                    </li>
                    <li>

                        
                        <a href="030%20%E5%A4%8D%E7%9B%98%207%20%E4%B8%80%E8%B5%B7%E6%9D%A5%E8%AF%BB%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9B%BD%E9%99%85%E9%A1%B6%E7%BA%A7%E4%BC%9A%E8%AE%AE%E8%AE%BA%E6%96%87.md.html">030 复盘 7 一起来读人工智能国际顶级会议论文.md</a>

                    </li>
                    <li>

                        
                        <a href="031%20%E7%BB%8F%E5%85%B8%E6%90%9C%E7%B4%A2%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95%EF%BC%9ATF-IDF%E5%8F%8A%E5%85%B6%E5%8F%98%E7%A7%8D.md.html">031 经典搜索核心算法：TF-IDF及其变种.md</a>

                    </li>
                    <li>

                        
                        <a href="032%20%E7%BB%8F%E5%85%B8%E6%90%9C%E7%B4%A2%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95%EF%BC%9ABM25%E5%8F%8A%E5%85%B6%E5%8F%98%E7%A7%8D%EF%BC%88%E5%86%85%E9%99%84%E5%85%A8%E5%B9%B4%E7%9B%AE%E5%BD%95%EF%BC%89.md.html">032 经典搜索核心算法：BM25及其变种（内附全年目录）.md</a>

                    </li>
                    <li>

                        
                        <a href="033%20%E7%BB%8F%E5%85%B8%E6%90%9C%E7%B4%A2%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95%EF%BC%9A%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%85%B6%E5%8F%98%E7%A7%8D.md.html">033 经典搜索核心算法：语言模型及其变种.md</a>

                    </li>
                    <li>

                        
                        <a href="034%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%EF%BC%9A%E5%8D%95%E7%82%B9%E6%B3%95%E6%8E%92%E5%BA%8F%E5%AD%A6%E4%B9%A0.md.html">034 机器学习排序算法：单点法排序学习.md</a>

                    </li>
                    <li>

                        
                        <a href="035%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%EF%BC%9A%E9%85%8D%E5%AF%B9%E6%B3%95%E6%8E%92%E5%BA%8F%E5%AD%A6%E4%B9%A0.md.html">035 机器学习排序算法：配对法排序学习.md</a>

                    </li>
                    <li>

                        
                        <a href="036%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%EF%BC%9A%E5%88%97%E8%A1%A8%E6%B3%95%E6%8E%92%E5%BA%8F%E5%AD%A6%E4%B9%A0.md.html">036 机器学习排序算法：列表法排序学习.md</a>

                    </li>
                    <li>

                        
                        <a href="037%20%E6%9F%A5%E8%AF%A2%E5%85%B3%E9%94%AE%E5%AD%97%E7%90%86%E8%A7%A3%E4%B8%89%E9%83%A8%E6%9B%B2%E4%B9%8B%E5%88%86%E7%B1%BB.md.html">037 查询关键字理解三部曲之分类.md</a>

                    </li>
                    <li>

                        
                        <a href="038%20%E6%9F%A5%E8%AF%A2%E5%85%B3%E9%94%AE%E5%AD%97%E7%90%86%E8%A7%A3%E4%B8%89%E9%83%A8%E6%9B%B2%E4%B9%8B%E8%A7%A3%E6%9E%90.md.html">038 查询关键字理解三部曲之解析.md</a>

                    </li>
                    <li>

                        
                        <a href="039%20%E6%9F%A5%E8%AF%A2%E5%85%B3%E9%94%AE%E5%AD%97%E7%90%86%E8%A7%A3%E4%B8%89%E9%83%A8%E6%9B%B2%E4%B9%8B%E6%89%A9%E5%B1%95.md.html">039 查询关键字理解三部曲之扩展.md</a>

                    </li>
                    <li>

                        
                        <a href="040%20%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F%E8%AF%84%E6%B5%8B%EF%BC%8C%E6%9C%89%E5%93%AA%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%8C%87%E6%A0%87%EF%BC%9F.md.html">040 搜索系统评测，有哪些基础指标？.md</a>

                    </li>
                    <li>

                        
                        <a href="041%20%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F%E8%AF%84%E6%B5%8B%EF%BC%8C%E6%9C%89%E5%93%AA%E4%BA%9B%E9%AB%98%E7%BA%A7%E6%8C%87%E6%A0%87%EF%BC%9F.md.html">041 搜索系统评测，有哪些高级指标？.md</a>

                    </li>
                    <li>

                        
                        <a href="042%20%E5%A6%82%E4%BD%95%E8%AF%84%E6%B5%8B%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%9C%A8%E7%BA%BF%E8%A1%A8%E7%8E%B0%EF%BC%9F.md.html">042 如何评测搜索系统的在线表现？.md</a>

                    </li>
                    <li>

                        
                        <a href="043%20%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E6%96%87%E6%A1%A3%E5%88%86%E7%B1%BB.md.html">043 文档理解第一步：文档分类.md</a>

                    </li>
                    <li>

                        
                        <a href="044%20%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3%E7%9A%84%E5%85%B3%E9%94%AE%E6%AD%A5%E9%AA%A4%EF%BC%9A%E6%96%87%E6%A1%A3%E8%81%9A%E7%B1%BB.md.html">044 文档理解的关键步骤：文档聚类.md</a>

                    </li>
                    <li>

                        
                        <a href="045%20%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3%E7%9A%84%E9%87%8D%E8%A6%81%E7%89%B9%E4%BE%8B%EF%BC%9A%E5%A4%9A%E6%A8%A1%E6%96%87%E6%A1%A3%E5%BB%BA%E6%A8%A1.md.html">045 文档理解的重要特例：多模文档建模.md</a>

                    </li>
                    <li>

                        
                        <a href="046%20%E5%A4%A7%E5%9E%8B%E6%90%9C%E7%B4%A2%E6%A1%86%E6%9E%B6%E5%AE%8F%E8%A7%82%E8%A7%86%E8%A7%92%EF%BC%9A%E5%8F%91%E5%B1%95%E3%80%81%E7%89%B9%E7%82%B9%E5%8F%8A%E8%B6%8B%E5%8A%BF.md.html">046 大型搜索框架宏观视角：发展、特点及趋势.md</a>

                    </li>
                    <li>

                        
                        <a href="047%20%E5%A4%9A%E8%BD%AE%E6%89%93%E5%88%86%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0.md.html">047 多轮打分系统概述.md</a>

                    </li>
                    <li>

                        
                        <a href="048%20%E6%90%9C%E7%B4%A2%E7%B4%A2%E5%BC%95%E5%8F%8A%E5%85%B6%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF%E6%A6%82%E8%BF%B0.md.html">048 搜索索引及其相关技术概述.md</a>

                    </li>
                    <li>

                        
                        <a href="049%20PageRank%E7%AE%97%E6%B3%95%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F.md.html">049 PageRank算法的核心思想是什么？.md</a>

                    </li>
                    <li>

                        
                        <a href="050%20%E7%BB%8F%E5%85%B8%E5%9B%BE%E7%AE%97%E6%B3%95%E4%B9%8BHITS.md.html">050 经典图算法之HITS.md</a>

                    </li>
                    <li>

                        
                        <a href="051%20%E7%A4%BE%E5%8C%BA%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E4%B9%8B%E6%A8%A1%E5%9D%97%E6%9C%80%E5%A4%A7%E5%8C%96.txt">051 社区检测算法之模块最大化</a>

                    </li>
                    <li>

                        
                        <a href="052%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%EF%BC%9ARankSVM.md.html">052 机器学习排序算法经典模型：RankSVM.md</a>

                    </li>
                    <li>

                        
                        <a href="053%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%EF%BC%9AGBDT.md.html">053 机器学习排序算法经典模型：GBDT.md</a>

                    </li>
                    <li>

                        
                        <a href="054%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%EF%BC%9ALambdaMART.md.html">054 机器学习排序算法经典模型：LambdaMART.md</a>

                    </li>
                    <li>

                        
                        <a href="055%20%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%EF%BC%9A%E6%B7%B1%E5%BA%A6%E7%BB%93%E6%9E%84%E5%8C%96%E8%AF%AD%E4%B9%89%E6%A8%A1%E5%9E%8B.md.html">055 基于深度学习的搜索算法：深度结构化语义模型.md</a>

                    </li>
                    <li>

                        
                        <a href="056%20%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%EF%BC%9A%E5%8D%B7%E7%A7%AF%E7%BB%93%E6%9E%84%E4%B8%8B%E7%9A%84%E9%9A%90%E5%90%AB%E8%AF%AD%E4%B9%89%E6%A8%A1%E5%9E%8B.md.html">056 基于深度学习的搜索算法：卷积结构下的隐含语义模型.md</a>

                    </li>
                    <li>

                        
                        <a href="057%20%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%EF%BC%9A%E5%B1%80%E9%83%A8%E5%92%8C%E5%88%86%E5%B8%83%E8%A1%A8%E5%BE%81%E4%B8%8B%E7%9A%84%E6%90%9C%E7%B4%A2%E6%A8%A1%E5%9E%8B.md.html">057 基于深度学习的搜索算法：局部和分布表征下的搜索模型.md</a>

                    </li>
                    <li>

                        
                        <a href="057%20%E5%A4%8D%E7%9B%98%201%20%E6%90%9C%E7%B4%A2%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%A8%A1%E5%9D%97.md.html">057 复盘 1 搜索核心技术模块.md</a>

                    </li>
                    <li>

                        
                        <a href="058%20%E7%AE%80%E5%8D%95%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%B8%80%EF%BC%9A%E5%9F%BA%E4%BA%8E%E6%B5%81%E8%A1%8C%E5%BA%A6%E7%9A%84%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B.md.html">058 简单推荐模型之一：基于流行度的推荐模型.md</a>

                    </li>
                    <li>

                        
                        <a href="059%20%E7%AE%80%E5%8D%95%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%BA%8C%EF%BC%9A%E5%9F%BA%E4%BA%8E%E7%9B%B8%E4%BC%BC%E4%BF%A1%E6%81%AF%E7%9A%84%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B.md.html">059 简单推荐模型之二：基于相似信息的推荐模型.md</a>

                    </li>
                    <li>

                        
                        <a href="060%20%E7%AE%80%E5%8D%95%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%B8%89%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E4%BF%A1%E6%81%AF%E7%9A%84%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B.md.html">060 简单推荐模型之三：基于内容信息的推荐模型.md</a>

                    </li>
                    <li>

                        
                        <a href="061%20%E5%9F%BA%E4%BA%8E%E9%9A%90%E5%8F%98%E9%87%8F%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%B8%80%EF%BC%9A%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.md.html">061 基于隐变量的模型之一：矩阵分解.md</a>

                    </li>
                    <li>

                        
                        <a href="062%20%E5%9F%BA%E4%BA%8E%E9%9A%90%E5%8F%98%E9%87%8F%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%BA%8C%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%9B%9E%E5%BD%92%E7%9A%84%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.md.html">062 基于隐变量的模型之二：基于回归的矩阵分解.md</a>

                    </li>
                    <li>

                        
                        <a href="063%20%E5%9F%BA%E4%BA%8E%E9%9A%90%E5%8F%98%E9%87%8F%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%B8%89%EF%BC%9A%E5%88%86%E8%A7%A3%E6%9C%BA.md.html">063 基于隐变量的模型之三：分解机.md</a>

                    </li>
                    <li>

                        
                        <a href="064%20%E9%AB%98%E7%BA%A7%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%B8%80%EF%BC%9A%E5%BC%A0%E9%87%8F%E5%88%86%E8%A7%A3%E6%A8%A1%E5%9E%8B.md.html">064 高级推荐模型之一：张量分解模型.md</a>

                    </li>
                    <li>

                        
                        <a href="065%20%E9%AB%98%E7%BA%A7%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%BA%8C%EF%BC%9A%E5%8D%8F%E5%90%8C%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.md.html">065 高级推荐模型之二：协同矩阵分解.md</a>

                    </li>
                    <li>

                        
                        <a href="066%20%E9%AB%98%E7%BA%A7%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%B8%89%EF%BC%9A%E4%BC%98%E5%8C%96%E5%A4%8D%E6%9D%82%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0.md.html">066 高级推荐模型之三：优化复杂目标函数.md</a>

                    </li>
                    <li>

                        
                        <a href="067%20%E6%8E%A8%E8%8D%90%E7%9A%84Exploit%E5%92%8CExplore%E7%AE%97%E6%B3%95%E4%B9%8B%E4%B8%80%EF%BC%9AEE%E7%AE%97%E6%B3%95%E7%BB%BC%E8%BF%B0.md.html">067 推荐的Exploit和Explore算法之一：EE算法综述.md</a>

                    </li>
                    <li>

                        
                        <a href="068%20%E6%8E%A8%E8%8D%90%E7%9A%84Exploit%E5%92%8CExplore%E7%AE%97%E6%B3%95%E4%B9%8B%E4%BA%8C%EF%BC%9AUCB%E7%AE%97%E6%B3%95.md.html">068 推荐的Exploit和Explore算法之二：UCB算法.md</a>

                    </li>
                    <li>

                        
                        <a href="069%20%E6%8E%A8%E8%8D%90%E7%9A%84Exploit%E5%92%8CExplore%E7%AE%97%E6%B3%95%E4%B9%8B%E4%B8%89%EF%BC%9A%E6%B1%A4%E6%99%AE%E6%A3%AE%E9%87%87%E6%A0%B7%E7%AE%97%E6%B3%95.md.html">069 推荐的Exploit和Explore算法之三：汤普森采样算法.md</a>

                    </li>
                    <li>

                        
                        <a href="070%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E6%B5%8B%E4%B9%8B%E4%B8%80%EF%BC%9A%E4%BC%A0%E7%BB%9F%E7%BA%BF%E4%B8%8B%E8%AF%84%E6%B5%8B.md.html">070 推荐系统评测之一：传统线下评测.md</a>

                    </li>
                    <li>

                        
                        <a href="071%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E6%B5%8B%E4%B9%8B%E4%BA%8C%EF%BC%9A%E7%BA%BF%E4%B8%8A%E8%AF%84%E6%B5%8B.md.html">071 推荐系统评测之二：线上评测.md</a>

                    </li>
                    <li>

                        
                        <a href="072%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E6%B5%8B%E4%B9%8B%E4%B8%89%EF%BC%9A%E6%97%A0%E5%81%8F%E5%B7%AE%E4%BC%B0%E8%AE%A1.md.html">072 推荐系统评测之三：无偏差估计.md</a>

                    </li>
                    <li>

                        
                        <a href="073%20%E7%8E%B0%E4%BB%A3%E6%8E%A8%E8%8D%90%E6%9E%B6%E6%9E%84%E5%89%96%E6%9E%90%E4%B9%8B%E4%B8%80%EF%BC%9A%E5%9F%BA%E4%BA%8E%E7%BA%BF%E4%B8%8B%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97%E7%9A%84%E6%8E%A8%E8%8D%90%E6%9E%B6%E6%9E%84.md.html">073 现代推荐架构剖析之一：基于线下离线计算的推荐架构.md</a>

                    </li>
                    <li>

                        
                        <a href="074%20%E7%8E%B0%E4%BB%A3%E6%8E%A8%E8%8D%90%E6%9E%B6%E6%9E%84%E5%89%96%E6%9E%90%E4%B9%8B%E4%BA%8C%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%B1%82%E6%90%9C%E7%B4%A2%E6%9E%B6%E6%9E%84%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.md.html">074 现代推荐架构剖析之二：基于多层搜索架构的推荐系统.md</a>

                    </li>
                    <li>

                        
                        <a href="075%20%E7%8E%B0%E4%BB%A3%E6%8E%A8%E8%8D%90%E6%9E%B6%E6%9E%84%E5%89%96%E6%9E%90%E4%B9%8B%E4%B8%89%EF%BC%9A%E5%A4%8D%E6%9D%82%E7%8E%B0%E4%BB%A3%E6%8E%A8%E8%8D%90%E6%9E%B6%E6%9E%84%E6%BC%AB%E8%B0%88.md.html">075 现代推荐架构剖析之三：复杂现代推荐架构漫谈.md</a>

                    </li>
                    <li>

                        
                        <a href="076%20%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%B8%80%EF%BC%9A%E5%8F%97%E9%99%90%E6%B3%A2%E5%85%B9%E6%9B%BC%E6%9C%BA.md.html">076 基于深度学习的推荐模型之一：受限波兹曼机.md</a>

                    </li>
                    <li>

                        
                        <a href="077%20%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%BA%8C%EF%BC%9A%E5%9F%BA%E4%BA%8ERNN%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.md.html">077 基于深度学习的推荐模型之二：基于RNN的推荐系统.md</a>

                    </li>
                    <li>

                        
                        <a href="078%20%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%B8%89%EF%BC%9A%E5%88%A9%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9D%A5%E6%89%A9%E5%B1%95%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.md.html">078 基于深度学习的推荐模型之三：利用深度学习来扩展推荐系统.md</a>

                    </li>
                    <li>

                        
                        <a href="078%20%E5%A4%8D%E7%9B%98%202%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%A8%A1%E5%9D%97.md.html">078 复盘 2 推荐系统核心技术模块.md</a>

                    </li>
                    <li>

                        
                        <a href="079%20%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0.md.html">079 广告系统概述.md</a>

                    </li>
                    <li>

                        
                        <a href="080%20%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.md.html">080 广告系统架构.md</a>

                    </li>
                    <li>

                        
                        <a href="081%20%E5%B9%BF%E5%91%8A%E5%9B%9E%E9%A6%88%E9%A2%84%E4%BC%B0%E7%BB%BC%E8%BF%B0.md.html">081 广告回馈预估综述.md</a>

                    </li>
                    <li>

                        
                        <a href="082%20Google%E7%9A%84%E7%82%B9%E5%87%BB%E7%8E%87%E7%B3%BB%E7%BB%9F%E6%A8%A1%E5%9E%8B.md.html">082 Google的点击率系统模型.md</a>

                    </li>
                    <li>

                        
                        <a href="083%20Facebook%E7%9A%84%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B.md.html">083 Facebook的广告点击率预估模型.md</a>

                    </li>
                    <li>

                        
                        <a href="084%20%E9%9B%85%E8%99%8E%E7%9A%84%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B.md.html">084 雅虎的广告点击率预估模型.md</a>

                    </li>
                    <li>

                        
                        <a href="085%20LinkedIn%E7%9A%84%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B.md.html">085 LinkedIn的广告点击率预估模型.md</a>

                    </li>
                    <li>

                        
                        <a href="086%20Twitter%E7%9A%84%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B.md.html">086 Twitter的广告点击率预估模型.md</a>

                    </li>
                    <li>

                        
                        <a href="087%20%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E7%9A%84%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B.md.html">087 阿里巴巴的广告点击率预估模型.md</a>

                    </li>
                    <li>

                        
                        <a href="088%20%E4%BB%80%E4%B9%88%E6%98%AF%E5%9F%BA%E4%BA%8E%E7%AC%AC%E4%BA%8C%E4%BB%B7%E4%BD%8D%E7%9A%84%E5%B9%BF%E5%91%8A%E7%AB%9E%E6%8B%8D%EF%BC%9F.md.html">088 什么是基于第二价位的广告竞拍？.md</a>

                    </li>
                    <li>

                        
                        <a href="089%20%E5%B9%BF%E5%91%8A%E7%9A%84%E7%AB%9E%E4%BB%B7%E7%AD%96%E7%95%A5%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84%EF%BC%9F.md.html">089 广告的竞价策略是怎样的？.md</a>

                    </li>
                    <li>

                        
                        <a href="090%20%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%E5%B9%BF%E5%91%8A%E7%9A%84%E7%AB%9E%E4%BB%B7%E7%AD%96%E7%95%A5%EF%BC%9F.md.html">090 如何优化广告的竞价策略？.md</a>

                    </li>
                    <li>

                        
                        <a href="091%20%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E5%B9%BF%E5%91%8A%E9%A2%84%E7%AE%97%EF%BC%9F.md.html">091 如何控制广告预算？.md</a>

                    </li>
                    <li>

                        
                        <a href="092%20%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE%E5%B9%BF%E5%91%8A%E7%AB%9E%E4%BB%B7%E7%9A%84%E5%BA%95%E4%BB%B7%EF%BC%9F.md.html">092 如何设置广告竞价的底价？.md</a>

                    </li>
                    <li>

                        
                        <a href="093%20%E8%81%8A%E4%B8%80%E8%81%8A%E7%A8%8B%E5%BA%8F%E5%8C%96%E7%9B%B4%E6%8E%A5%E8%B4%AD%E4%B9%B0%E5%92%8C%E5%B9%BF%E5%91%8A%E6%9C%9F%E8%B4%A7.md.html">093 聊一聊程序化直接购买和广告期货.md</a>

                    </li>
                    <li>

                        
                        <a href="094%20%E5%BD%92%E5%9B%A0%E6%A8%A1%E5%9E%8B%EF%BC%9A%E5%A6%82%E4%BD%95%E6%9D%A5%E8%A1%A1%E9%87%8F%E5%B9%BF%E5%91%8A%E7%9A%84%E6%9C%89%E6%95%88%E6%80%A7.md.html">094 归因模型：如何来衡量广告的有效性.md</a>

                    </li>
                    <li>

                        
                        <a href="095%20%E5%B9%BF%E5%91%8A%E6%8A%95%E6%94%BE%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%8F%97%E4%BC%97%EF%BC%9F%E5%A6%82%E4%BD%95%E6%89%A9%E5%B1%95%E5%8F%97%E4%BC%97%E7%BE%A4%EF%BC%9F.md.html">095 广告投放如何选择受众？如何扩展受众群？.md</a>

                    </li>
                    <li>

                        
                        <a href="096%20%E5%A4%8D%E7%9B%98%204%20%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%A8%A1%E5%9D%97.md.html">096 复盘 4 广告系统核心技术模块.md</a>

                    </li>
                    <li>

                        
                        <a href="096%20%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%E6%9D%A5%E6%A3%80%E6%B5%8B%E5%B9%BF%E5%91%8A%E6%AC%BA%E8%AF%88%EF%BC%9F.md.html">096 如何利用机器学习技术来检测广告欺诈？.md</a>

                    </li>
                    <li>

                        <a class="current-tab" href="097%20LDA%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F.md.html">097 LDA模型的前世今生.md</a>
                        

                    </li>
                    <li>

                        
                        <a href="098%20LDA%E5%8F%98%E7%A7%8D%E6%A8%A1%E5%9E%8B%E7%9F%A5%E5%A4%9A%E5%B0%91.md.html">098 LDA变种模型知多少.md</a>

                    </li>
                    <li>

                        
                        <a href="099%20%E9%92%88%E5%AF%B9%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96LDA%E7%AE%97%E6%B3%95%EF%BC%9F.md.html">099 针对大规模数据，如何优化LDA算法？.md</a>

                    </li>
                    <li>

                        
                        <a href="100%20%E5%9F%BA%E7%A1%80%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%B8%80%EF%BC%9A%E9%9A%90%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90.md.html">100 基础文本分析模型之一：隐语义分析.md</a>

                    </li>
                    <li>

                        
                        <a href="101%20%E5%9F%BA%E7%A1%80%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%BA%8C%EF%BC%9A%E6%A6%82%E7%8E%87%E9%9A%90%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90.md.html">101 基础文本分析模型之二：概率隐语义分析.md</a>

                    </li>
                    <li>

                        
                        <a href="102%20%E5%9F%BA%E7%A1%80%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%B8%89%EF%BC%9AEM%E7%AE%97%E6%B3%95.md.html">102 基础文本分析模型之三：EM算法.md</a>

                    </li>
                    <li>

                        
                        <a href="103%20%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81Word2Vec%E7%AE%97%E6%B3%95%EF%BC%9F.md.html">103 为什么需要Word2Vec算法？.md</a>

                    </li>
                    <li>

                        
                        <a href="104%20Word2Vec%E7%AE%97%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B%E6%89%A9%E5%B1%95%E6%A8%A1%E5%9E%8B%EF%BC%9F.md.html">104 Word2Vec算法有哪些扩展模型？.md</a>

                    </li>
                    <li>

                        
                        <a href="105%20Word2Vec%E7%AE%97%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B%E5%BA%94%E7%94%A8%EF%BC%9F.md.html">105 Word2Vec算法有哪些应用？.md</a>

                    </li>
                    <li>

                        
                        <a href="106%20%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%88%A9%E5%99%A8%EF%BC%9ARNN%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84.md.html">106 序列建模的深度学习利器：RNN基础架构.md</a>

                    </li>
                    <li>

                        
                        <a href="107%20%E5%9F%BA%E4%BA%8E%E9%97%A8%E6%9C%BA%E5%88%B6%E7%9A%84RNN%E6%9E%B6%E6%9E%84%EF%BC%9ALSTM%E4%B8%8EGRU.md.html">107 基于门机制的RNN架构：LSTM与GRU.md</a>

                    </li>
                    <li>

                        
                        <a href="108%20RNN%E5%9C%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%AD%E6%9C%89%E5%93%AA%E4%BA%9B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9F.md.html">108 RNN在自然语言处理中有哪些应用场景？.md</a>

                    </li>
                    <li>

                        
                        <a href="109%20%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F%E4%B9%8B%E7%BB%8F%E5%85%B8%E7%9A%84%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B.md.html">109 对话系统之经典的对话模型.md</a>

                    </li>
                    <li>

                        
                        <a href="110%20%E4%BB%BB%E5%8A%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F%E6%9C%89%E5%93%AA%E4%BA%9B%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9%EF%BC%9F.md.html">110 任务型对话系统有哪些技术要点？.md</a>

                    </li>
                    <li>

                        
                        <a href="111%20%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%9C%89%E5%93%AA%E4%BA%9B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9%EF%BC%9F.md.html">111 聊天机器人有哪些核心技术要点？.md</a>

                    </li>
                    <li>

                        
                        <a href="112%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%96%87%E6%A1%A3%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB%EF%BC%9F.md.html">112 什么是文档情感分类？.md</a>

                    </li>
                    <li>

                        
                        <a href="113%20%E5%A6%82%E4%BD%95%E6%9D%A5%E6%8F%90%E5%8F%96%E6%83%85%E6%84%9F%E5%AE%9E%E4%BD%93%E5%92%8C%E6%96%B9%E9%9D%A2%E5%91%A2%EF%BC%9F.md.html">113 如何来提取情感实体和方面呢？.md</a>

                    </li>
                    <li>

                        
                        <a href="114%20%E5%A4%8D%E7%9B%98%203%20%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%8F%8A%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%A8%A1%E5%9D%97.md.html">114 复盘 3 自然语言处理及文本处理核心技术模块.md</a>

                    </li>
                    <li>

                        
                        <a href="114%20%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E4%B8%AD%E5%A6%82%E4%BD%95%E5%81%9A%E6%84%8F%E8%A7%81%E6%80%BB%E7%BB%93%E5%92%8C%E6%90%9C%E7%B4%A2%EF%BC%9F.md.html">114 文本情感分析中如何做意见总结和搜索？.md</a>

                    </li>
                    <li>

                        
                        <a href="115%20%E4%BB%80%E4%B9%88%E6%98%AF%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%EF%BC%9F.md.html">115 什么是计算机视觉？.md</a>

                    </li>
                    <li>

                        
                        <a href="116%20%E6%8E%8C%E6%8F%A1%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%93%8D%E4%BD%9C.md.html">116 掌握计算机视觉任务的基础模型和操作.md</a>

                    </li>
                    <li>

                        
                        <a href="117%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E9%9A%BE%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9F.md.html">117 计算机视觉中的特征提取难在哪里？.md</a>

                    </li>
                    <li>

                        
                        <a href="118%20%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%8A%80%E6%9C%AF%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8.md.html">118 基于深度学习的计算机视觉技术（一）：深度神经网络入门.md</a>

                    </li>
                    <li>

                        
                        <a href="119%20%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%8A%80%E6%9C%AF%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B.md.html">119 基于深度学习的计算机视觉技术（二）：基本的深度学习模型.md</a>

                    </li>
                    <li>

                        
                        <a href="120%20%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%8A%80%E6%9C%AF%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BC%98%E5%8C%96.md.html">120 基于深度学习的计算机视觉技术（三）：深度学习模型的优化.md</a>

                    </li>
                    <li>

                        
                        <a href="121%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E9%A2%86%E5%9F%9F%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AAlexNet.md.html">121 计算机视觉领域的深度学习模型（一）：AlexNet.md</a>

                    </li>
                    <li>

                        
                        <a href="122%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E9%A2%86%E5%9F%9F%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9AVGG%20&amp;%20GoogleNet.md.html">122 计算机视觉领域的深度学习模型（二）：VGG &amp; GoogleNet.md</a>

                    </li>
                    <li>

                        
                        <a href="123%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E9%A2%86%E5%9F%9F%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AResNet.md.html">123 计算机视觉领域的深度学习模型（三）：ResNet.md</a>

                    </li>
                    <li>

                        
                        <a href="124%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E9%AB%98%E7%BA%A7%E8%AF%9D%E9%A2%98%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%9B%BE%E5%83%8F%E7%89%A9%E4%BD%93%E8%AF%86%E5%88%AB%E5%92%8C%E5%88%86%E5%89%B2.md.html">124 计算机视觉高级话题（一）：图像物体识别和分割.md</a>

                    </li>
                    <li>

                        
                        <a href="125%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E9%AB%98%E7%BA%A7%E8%AF%9D%E9%A2%98%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94.md.html">125 计算机视觉高级话题（二）：视觉问答.md</a>

                    </li>
                    <li>

                        
                        <a href="126%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E9%AB%98%E7%BA%A7%E8%AF%9D%E9%A2%98%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E4%BA%A7%E7%94%9F%E5%BC%8F%E6%A8%A1%E5%9E%8B.md.html">126 计算机视觉高级话题（三）：产生式模型.md</a>

                    </li>
                    <li>

                        
                        <a href="126%E5%A4%8D%E7%9B%98%205%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%A8%A1%E5%9D%97.md.html">126复盘 5 计算机视觉核心技术模块.md</a>

                    </li>
                    <li>

                        
                        <a href="127%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E5%9F%BA%E7%A1%80%E8%83%BD%E5%8A%9B%E4%B9%8B%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1.md.html">127 数据科学家基础能力之概率统计.md</a>

                    </li>
                    <li>

                        
                        <a href="128%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E5%9F%BA%E7%A1%80%E8%83%BD%E5%8A%9B%E4%B9%8B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.md.html">128 数据科学家基础能力之机器学习.md</a>

                    </li>
                    <li>

                        
                        <a href="129%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E5%9F%BA%E7%A1%80%E8%83%BD%E5%8A%9B%E4%B9%8B%E7%B3%BB%E7%BB%9F.md.html">129 数据科学家基础能力之系统.md</a>

                    </li>
                    <li>

                        
                        <a href="130%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E9%AB%98%E9%98%B6%E8%83%BD%E5%8A%9B%E4%B9%8B%E5%88%86%E6%9E%90%E4%BA%A7%E5%93%81.md.html">130 数据科学家高阶能力之分析产品.md</a>

                    </li>
                    <li>

                        
                        <a href="131%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E9%AB%98%E9%98%B6%E8%83%BD%E5%8A%9B%E4%B9%8B%E8%AF%84%E4%BC%B0%E4%BA%A7%E5%93%81.md.html">131 数据科学家高阶能力之评估产品.md</a>

                    </li>
                    <li>

                        
                        <a href="132%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E9%AB%98%E9%98%B6%E8%83%BD%E5%8A%9B%E4%B9%8B%E5%A6%82%E4%BD%95%E7%B3%BB%E7%BB%9F%E6%8F%90%E5%8D%87%E4%BA%A7%E5%93%81%E6%80%A7%E8%83%BD.md.html">132 数据科学家高阶能力之如何系统提升产品性能.md</a>

                    </li>
                    <li>

                        
                        <a href="133%20%E8%81%8C%E5%9C%BA%E8%AF%9D%E9%A2%98%EF%BC%9A%E5%BD%93%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E9%81%87%E8%A7%81%E4%BA%A7%E5%93%81%E5%9B%A2%E9%98%9F.md.html">133 职场话题：当数据科学家遇见产品团队.md</a>

                    </li>
                    <li>

                        
                        <a href="134%20%E8%81%8C%E5%9C%BA%E8%AF%9D%E9%A2%98%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E5%BA%94%E8%81%98%E8%A6%81%E5%85%B7%E5%A4%87%E5%93%AA%E4%BA%9B%E8%83%BD%E5%8A%9B%EF%BC%9F.md.html">134 职场话题：数据科学家应聘要具备哪些能力？.md</a>

                    </li>
                    <li>

                        
                        <a href="135%20%E8%81%8C%E5%9C%BA%E8%AF%9D%E9%A2%98%EF%BC%9A%E8%81%8A%E8%81%8A%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E7%9A%84%E8%81%8C%E5%9C%BA%E8%A7%84%E5%88%92.md.html">135 职场话题：聊聊数据科学家的职场规划.md</a>

                    </li>
                    <li>

                        
                        <a href="136%20%E5%A6%82%E4%BD%95%E7%BB%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%9B%A2%E9%98%9F%EF%BC%9F.md.html">136 如何组建一个数据科学团队？.md</a>

                    </li>
                    <li>

                        
                        <a href="137%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%9B%A2%E9%98%9F%E5%85%BB%E6%88%90%EF%BC%9A%E7%94%B5%E8%AF%9D%E9%9D%A2%E8%AF%95%E6%8C%87%E5%8D%97.md.html">137 数据科学团队养成：电话面试指南.md</a>

                    </li>
                    <li>

                        
                        <a href="138%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%9B%A2%E9%98%9F%E5%85%BB%E6%88%90%EF%BC%9AOnsite%E9%9D%A2%E8%AF%95%E9%9D%A2%E9%9D%A2%E8%A7%82.md.html">138 数据科学团队养成：Onsite面试面面观.md</a>

                    </li>
                    <li>

                        
                        <a href="139%20%E6%88%90%E4%B8%BA%E9%A6%99%E9%A5%BD%E9%A5%BD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%EF%BC%8C%E5%A6%82%E4%BD%95%E8%A1%A1%E9%87%8F%E4%BB%96%E4%BB%AC%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%91%A2%EF%BC%9F.md.html">139 成为香饽饽的数据科学家，如何衡量他们的工作呢？.md</a>

                    </li>
                    <li>

                        
                        <a href="140%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E6%9B%B4%E6%96%B0%E5%91%A8%E6%9C%9F%E5%8F%AA%E6%9C%895%EF%BD%9E6%E5%B9%B4%EF%BC%8C%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E5%A6%82%E4%BD%95%E5%9F%B9%E5%85%BB%EF%BC%9F.md.html">140 人工智能领域知识体系更新周期只有5～6年，数据科学家如何培养？.md</a>

                    </li>
                    <li>

                        
                        <a href="141%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E5%9B%A2%E9%98%9F%E7%BB%84%E7%BB%87%E6%9E%B6%E6%9E%84%EF%BC%9A%E6%B0%B4%E5%B9%B3%E8%BF%98%E6%98%AF%E5%9E%82%E7%9B%B4%EF%BC%8C%E8%BF%99%E6%98%AF%E4%B8%AA%E9%97%AE%E9%A2%98.md.html">141 数据科学家团队组织架构：水平还是垂直，这是个问题.md</a>

                    </li>
                    <li>

                        
                        <a href="142%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E5%BF%85%E5%A4%87%E5%A5%97%E8%B7%AF%E4%B9%8B%E4%B8%80%EF%BC%9A%E6%90%9C%E7%B4%A2%E5%A5%97%E8%B7%AF.md.html">142 数据科学家必备套路之一：搜索套路.md</a>

                    </li>
                    <li>

                        
                        <a href="143%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E5%BF%85%E5%A4%87%E5%A5%97%E8%B7%AF%E4%B9%8B%E4%BA%8C%EF%BC%9A%E6%8E%A8%E8%8D%90%E5%A5%97%E8%B7%AF.md.html">143 数据科学家必备套路之二：推荐套路.md</a>

                    </li>
                    <li>

                        
                        <a href="144%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E5%BF%85%E5%A4%87%E5%A5%97%E8%B7%AF%E4%B9%8B%E4%B8%89%EF%BC%9A%E5%B9%BF%E5%91%8A%E5%A5%97%E8%B7%AF.md.html">144 数据科学家必备套路之三：广告套路.md</a>

                    </li>
                    <li>

                        
                        <a href="145%20%E5%A6%82%E4%BD%95%E5%81%9A%E5%A5%BD%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A1%B9%E7%9B%AE%E7%9A%84%E7%AE%A1%E7%90%86%EF%BC%9F.md.html">145 如何做好人工智能项目的管理？.md</a>

                    </li>
                    <li>

                        
                        <a href="146%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%9B%A2%E9%98%9F%E5%BF%85%E5%A4%87%E7%9A%84%E5%B7%A5%E7%A8%8B%E6%B5%81%E7%A8%8B%E4%B8%89%E9%83%A8%E6%9B%B2.md.html">146 数据科学团队必备的工程流程三部曲.md</a>

                    </li>
                    <li>

                        
                        <a href="147%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%9B%A2%E9%98%9F%E6%80%8E%E4%B9%88%E9%80%89%E6%8B%A9%E4%BA%A7%E5%93%81%E5%92%8C%E9%A1%B9%E7%9B%AE%EF%BC%9F.md.html">147 数据科学团队怎么选择产品和项目？.md</a>

                    </li>
                    <li>

                        
                        <a href="148%20%E6%9B%BE%E7%BB%8F%E8%BE%89%E7%85%8C%E7%9A%84%E9%9B%85%E8%99%8E%E7%A0%94%E7%A9%B6%E9%99%A2.md.html">148 曾经辉煌的雅虎研究院.md</a>

                    </li>
                    <li>

                        
                        <a href="149%20%E5%BE%AE%E8%BD%AF%E7%A0%94%E7%A9%B6%E9%99%A2%EF%BC%9A%E5%B7%A5%E4%B8%9A%E7%95%8C%E7%A0%94%E7%A9%B6%E6%9C%BA%E6%9E%84%E7%9A%84%E6%A5%B7%E6%A8%A1.md.html">149 微软研究院：工业界研究机构的楷模.md</a>

                    </li>
                    <li>

                        
                        <a href="150%20%E5%A4%8D%E7%9B%98%206%20%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%9B%A2%E9%98%9F%E6%98%AF%E6%80%8E%E4%B9%88%E5%85%BB%E6%88%90%E7%9A%84%EF%BC%9F.md.html">150 复盘 6 数据科学家与数据科学团队是怎么养成的？.md</a>

                    </li>
                    <li>

                        
                        <a href="150%20%E8%81%8A%E4%B8%80%E8%81%8A%E8%B0%B7%E6%AD%8C%E7%89%B9%E7%AB%8B%E7%8B%AC%E8%A1%8C%E7%9A%84%E6%B7%B7%E5%90%88%E5%9E%8B%E7%A0%94%E7%A9%B6.md.html">150 聊一聊谷歌特立独行的混合型研究.md</a>

                    </li>
                    <li>

                        
                        <a href="151%20%E7%B2%BE%E8%AF%BBAlphaGo%20Zero%E8%AE%BA%E6%96%87.md.html">151 精读AlphaGo Zero论文.md</a>

                    </li>
                    <li>

                        
                        <a href="152%202017%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%8F%91%E5%B1%95%E7%9B%98%E7%82%B9.md.html">152 2017人工智能技术发展盘点.md</a>

                    </li>
                    <li>

                        
                        <a href="153%20%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E5%AD%A6%E4%B9%A0%E5%9B%BD%E9%99%85%E9%A1%B6%E7%BA%A7%E5%AD%A6%E6%9C%AF%E4%BC%9A%E8%AE%AE%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%9F.md.html">153 如何快速学习国际顶级学术会议的内容？.md</a>

                    </li>
                    <li>

                        
                        <a href="154%20%E5%9C%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A2%86%E5%9F%9F%EF%BC%8C%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E6%89%BE%E5%88%B0%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%88%87%E5%85%A5%E7%82%B9%EF%BC%9F.md.html">154 在人工智能领域，如何快速找到学习的切入点？.md</a>

                    </li>
                    <li>

                        
                        <a href="155%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E9%80%89%E6%8B%A9%EF%BC%8C%E8%AF%A5%E4%BB%8E%E5%93%AA%E9%87%8C%E8%8E%B7%E5%BE%97%E7%81%B5%E6%84%9F%EF%BC%9F.md.html">155 人工智能技术选择，该从哪里获得灵感？.md</a>

                    </li>
                    <li>

                        
                        <a href="156%20%E5%86%85%E5%8F%82%E7%89%B9%E5%88%8A%20%E5%92%8C%E4%BD%A0%E8%81%8A%E8%81%8A%E6%AF%8F%E4%B8%AA%E4%BA%BA%E9%83%BD%E5%85%B3%E5%BF%83%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%83%AD%E7%82%B9%E8%AF%9D%E9%A2%98.md.html">156 内参特刊 和你聊聊每个人都关心的人工智能热点话题.md</a>

                    </li>
                    <li>

                        
                        <a href="156%20%E8%BF%91%E5%9C%A8%E5%92%AB%E5%B0%BA%EF%BC%8C%E8%B5%B0%E8%BF%9B%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%A0%94%E7%A9%B6.md.html">156 近在咫尺，走进人工智能研究.md</a>

                    </li>
                    <li>

                        
                        <a href="%E7%BB%93%E6%9D%9F%E8%AF%AD%20%E9%9B%84%E5%85%B3%E6%BC%AB%E9%81%93%E7%9C%9F%E5%A6%82%E9%93%81%EF%BC%8C%E8%80%8C%E4%BB%8A%E8%BF%88%E6%AD%A5%E4%BB%8E%E5%A4%B4%E8%B6%8A.md.html">结束语 雄关漫道真如铁，而今迈步从头越.md</a>

                    </li>
                </ul>

            </div>
        </div>

        <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
            <div class="sidebar-toggle-inner"></div>
        </div>

        <script>
            function add_inner() {
                let inner = document.querySelector('.sidebar-toggle-inner')
                inner.classList.add('show')
            }

            function remove_inner() {
                let inner = document.querySelector('.sidebar-toggle-inner')
                inner.classList.remove('show')
            }

            function sidebar_toggle() {
                let sidebar_toggle = document.querySelector('.sidebar-toggle')
                let sidebar = document.querySelector('.book-sidebar')
                let content = document.querySelector('.off-canvas-content')
                if (sidebar_toggle.classList.contains('extend')) { // show
                    sidebar_toggle.classList.remove('extend')
                    sidebar.classList.remove('hide')
                    content.classList.remove('extend')
                } else { // hide
                    sidebar_toggle.classList.add('extend')
                    sidebar.classList.add('hide')
                    content.classList.add('extend')
                }
            }


            function open_sidebar() {
                let sidebar = document.querySelector('.book-sidebar')
                let overlay = document.querySelector('.off-canvas-overlay')
                sidebar.classList.add('show')
                overlay.classList.add('show')
            }
            function hide_canvas() {
                let sidebar = document.querySelector('.book-sidebar')
                let overlay = document.querySelector('.off-canvas-overlay')
                sidebar.classList.remove('show')
                overlay.classList.remove('show')
            }

        </script>

        <div class="off-canvas-content">
            <div class="columns">
                <div class="column col-12 col-lg-12">
                    <div class="book-navbar">
                        <!-- For Responsive Layout -->
                        <header class="navbar">
                            <section class="navbar-section">
                                <a onclick="open_sidebar()">
                                    <i class="icon icon-menu"></i>
                                </a>
                            </section>
                        </header>
                    </div>
                    <div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
                        <div class="book-post">
                            <p id="tip" align="center"></p>
                            <div><h1>097 LDA模型的前世今生</h1>
<p>在文本挖掘中，有一项重要的工作就是分析和挖掘出文本中隐含的结构信息，而不依赖任何提前标注的信息。今天我要介绍的是一个叫做<strong>LDA</strong>（Latent Dirichlet Allocation）的模型，它在过去十年里开启了一个领域叫<strong>主题模型</strong>。</p>
<p>从LDA提出后，不少学者都利用它来分析各式各样的文档数据，从新闻数据到医药文档，从考古文献到政府公文。一段时间内，LDA成了分析文本信息的标准工具。从最原始的LDA发展出来的各类模型变种，则被应用到了多种数据类型上，包括图像、音频、混合信息、推荐系统、文档检索等等，各类主题模型变种层出不穷。下面我来简单剖析一下LDA这个模型，聊聊它的模型描述以及训练方法等基础知识。</p>
<h2>LDA的背景介绍</h2>
<p>LDA的论文作者是戴维·布雷（David Blei）、吴恩达和迈克尔·乔丹（Michael Jordan）。这三位都是今天机器学习界炙手可热的人物。论文最早发表在2002年的神经信息处理系统大会（Neural Information Processing Systems，简称NIPS）上，然后长文章（Long Paper）于2003年在机器学习顶级期刊《机器学习研究杂志》（Journal of Machine Learning Research）上发表。迄今为止，这篇论文已经有超过1万9千次的引用数，也成了机器学习史上的重要文献之一。</p>
<p>论文发表的时候，戴维·布雷还在加州大学伯克利分校迈克尔手下攻读博士。吴恩达当时刚刚从迈克尔手下博士毕业来到斯坦福大学任教。戴维 2004年从伯克利毕业后，先到卡内基梅隆大学跟随统计学权威教授约翰·拉弗蒂（John Lafferty）做了两年的博士后学者，然后又到东部普林斯顿大学任教职，先后担任助理教授和副教授。2014年转到纽约哥伦比亚大学任统计系和计算机系的正教授。戴维在2010年获得斯隆奖（Alfred P. Sloan Fellowship，美国声誉极高的奖励研究人员的奖项，不少诺贝尔奖获得者均在获得诺贝尔奖多年之前获得过此奖），紧接着又在2011年获得总统青年科学家和工程师早期成就奖（Presidential Early Career Award for Scientists and Engineers，简称PECASE）。目前他所有论文的引用数超过了4万9千次 。</p>
<p>吴恩达在斯坦福晋升到副教授后，2011年到2012年在Google工作，开启了谷歌大脑（Google Brain）的项目来训练大规模的深度学习模型，是深度学习的重要人物和推动者之一。2012年他合作创建了在线学习平台Coursera，可以说是打开了慕课（Massive Open Online Course，简称MOOC）运动的大门。之后吴恩达从2014年到2017年间担任百度首席科学家，并创建和运行了百度在北美的研究机构。目前他所有论文的引用数超过8万3千次。</p>
<p>文章的第三作者迈克尔·乔丹是机器学习界的泰斗人物。他自1998年在加州大学伯克利任教至今，是美国三个科学院院士（American Academy of Arts and Sciences、National Academy of Engineering以及National Academy of Sciences），是诸多学术和专业组织的院士（比如ACM、IEEE、AAAI、SIAM等）。迈克尔可以说是桃李满天下，而且其徒子徒孙也已经遍布整个机器学习领域，不少都是学术权威。他的所有论文有多达12万次以上的引用量。</p>
<p>值得注意的是，对于三位作者来说，LDA论文都是他们单篇论文引用次数最多的文章。</p>
<h2>LDA模型</h2>
<p>要描述LDA模型，就要说一下LDA模型所属的<strong>产生式模型</strong>（Generative Model）的背景。产生式模型是相对于<strong>判别式模型</strong>（Discriminative Model）而说的。这里，我们假设需要建模的数据有特征信息，也就是通常说的X，以及标签信息，也就是通常所说的Y。</p>
<p>判别式模型常常直接对Y的产生过程（Generative Process)进行描述，而对特征信息本身不予建模。这使得判别式模型天生就成为构建分类器或者回归分析的有利工具。而产生式模型则要同时对X和Y建模，这使得产生式模型更适合做无标签的数据分析，比如聚类。当然，因为产生式模型要对比较多的信息进行建模，所以一般认为对于同一个数据而言，产生式模型要比判别式模型更难以学习。</p>
<p>一般来说，产生式模型希望通过一个产生过程来帮助读者理解一个模型。注意，这个产生过程本质是描述一个<strong>联合概率分布</strong>（Joint Distribution）的分解过程。也就是说，这个过程是一个虚拟过程，真实的数据往往并不是这样产生的。这样的产生过程是模型的一个假设，一种描述。任何一个产生过程都可以在数学上完全等价一个联合概率分布。</p>
<p>LDA的产生过程描述了文档以及文档中文字的生成过程。在原始的LDA论文中，作者们描述了对于每一个文档而言有这么一种生成过程：</p>
<ol>
<li>首先，从一个全局的泊松（Poisson）参数为β的分布中生成一个文档的长度N；</li>
<li>从一个全局的狄利克雷（Dirichlet）参数为α的分布中生成一个当前文档的θ；</li>
<li>然后对于当前文档长度N的每一个字执行以下两步，一是从以θ为参数的多项（Multinomial）分布中生成一个主题（Topic）的下标（Index）z_n；二是从以φ和z共同为参数的多项分布中产生一个字（Word）w_n。</li>
</ol>
<p><img src="assets/3a199f87bc6ebdae0eea8dbe8fbe1467.png" alt="img" /></p>
<p>从这个描述我们可以马上得到这些重要的模型信息。第一，我们有一个维度是K乘以V的主题矩阵（Topic Matrix）。其中每一行都是一个φ，也就是某一个生成字的多项分布。当然，这个主题矩阵我们在事先并不知道，是需要学习得到的。另外，对每一个文档而言，θ是一个长度为K的向量，用于描述当前文档在K个主题上的分布。产生过程告诉我们，我们对于文档中的每一个字，都先从这个θ向量中产生一个下标，用于告诉我们现在要从主题矩阵中的哪一行去生成当前的字。</p>
<p>这个产生模型是原论文最初提出的，有两点值得注意。</p>
<p>第一，原始论文为了完整性，提出了使用一个泊松分布来描述文档的长度这一变化信息。然而，从模型的参数和隐变量的角度来说，这个假设并不影响整个模型，最终作者在文章中去除了这个信息的讨论。在主题模型的研究中，也较少有文献专注这个信息。</p>
<p>第二，原始论文并没有在主题矩阵上放置全局的狄利克雷分布作为先验概率分布。这一缺失在后续所有的主题模型文献中得到修正。于是今天标准的LDA模型有两类狄利克雷的先验信息，一类是文档主题分布的先验，参数是α，一类是主题矩阵的先验，参数是β。</p>
<p>文章作者们把这个模型和当时的一系列其他模型进行了对比。比如说，LDA并不是所谓的狄利克雷-多项（Dirichlet-Multinomial）聚类模型。这里，LDA对于每个文档的每一个字都有一个主题下标。也就是说，从文档聚类的角度来看，LDA是没有一个文档统一的聚类标签，而是每个字有一个聚类标签，在这里就是主题。这也是LDA是<strong>Mixed-Membership模型</strong>的原因——每个字有可能属于不同的类别、每个文档也有可能属于不同的类别。</p>
<p>LDA很类似在2000年初提出的另外一类更简单的主题模型——概率隐形语义索引（Probabilistic Latent Semantic Indexing），简称<strong>PLSI</strong>。其实从本质上来说，LDA借用了PLSI的基本架构，只不过在每个文档的主题分布向量上放置了狄利克雷的先验概率，以及在主题矩阵上放置了另外一个狄利克雷的先验概率。</p>
<p>尽管看上去这是一个非常小的改动，但是这样做的结果则是LDA的参数个数并不随着文档数目的增加而增加。那么，相对于PLSI来说，LDA并不容易对训练数据<strong>过度拟合</strong>（Overfitting）。</p>
<p>值得注意的，原始文章说过度拟合主要是指，对于PLSI而言，文档的主题分布向量是必须需要学习的，而这个向量对于LDA是可以被忽略或者说是并不需要保存的中间变量。然而在实际的应用中，我们其实常常也需要这个向量的信息，因此这部分对于过度拟合的讨论在后来的应用中并没有特别体现。</p>
<h2>LDA模型的训练和结果</h2>
<p>LDA虽然从某种意义上来说仅仅是在PLSI上增加了先验信息。然而，这一个改动为整个模型的训练学习带来了非常大的挑战。应该说，整个LDA的学习直到模型提出后近10年，才随着<strong>随机变分推理</strong>（Stochastic Variational Inference）的提出以及基于<strong>别名方法</strong>（Alias Method）的抽样算法（Sampling Method）而得以真正的大规模化。一直以来，LDA的训练学习都是一件很困难的事情。</p>
<p>不像PLSI可以依靠<strong>最大期望（EM）算法</strong>得以比较完美的解决，传统上，LDA的学习属于<strong>贝叶斯推理</strong>（Bayesian Inference），而在2000年代初期，只有<strong>马尔科夫蒙特卡洛</strong>（Markov chain Monte Carlo），简称MCMC，以及迈克尔·乔丹等人推崇的<strong>变分推理</strong>（Variational Inference），简称VI，作为工具可以解决。这篇文章因为出自迈克尔的实验室，当仁不让地选择了VI。比较有意思的是，后续大多数LDA相关的论文都选择了MCMC为主的<strong>吉布斯</strong>（Gibbs）采样来作为学习算法。</p>
<p>VI的完整讲解无法在本文涵盖。从最高的层次上来理解，VI是选取一整组简单的、可以优化的所谓变分分布（Variational Distribution）来逼近整个模型的后验概率分布。当然，由于这组分布的选取，有可能会为模型带来不小的误差。不过好处则是这样就把贝叶斯推理的问题转化成了优化问题。</p>
<p>从LDA的角度来讲，就是要为θ以及z选取一组等价的分布，只不过更加简单，更不依赖其他的信息。在VI进行更新θ以及z的时候，算法可以根据当前的θ以及z的最新值，更新α的值（这里的讨论依照原始的LDA论文，忽略了β的信息）。整个流程俗称<strong>变分最大期望（Variational EM）算法</strong>。</p>
<p>文章在TREC AP的文档数据中做了实验。首先，作者们使用了一个叫<strong>困惑度</strong>（Perplexity）的评估值来衡量文档的建模有效程度，这个值越低越好。LDA在好几个数据集中都明显好于PLSI以及其他更加简单的模型。从这篇文章之后，主题模型的发展和对比都离不开困惑度的比较，也算是开启了一个新时代。</p>
<p>然后，作者们展示了利用LDA来做文档分类，也就是利用文档主题向量来作为文档的特征，从而放入分类器中加以分类。作者们展示了LDA作为文档分类特征的有力证据，在数据比较少的情况下优于文本本身的特征。不过总体说来，在原始的LDA论文中，作者们并没有特别多地展现出LDA的所有可能性。</p>
<h2>小结</h2>
<p>今天我为你梳理了LDA提出的背景以及这篇论文所引领的整个领域的情况。你需要掌握的核心要点：第一，论文作者们目前的状态；第二，LDA模型本身和它的一些特点；第三，LDA的训练流程概况以及在原始文章中的实验结果。</p>
<p>最后，我为你留一个思考题：LDA的产生过程决定了对于一个文本而言，每个字都可能来自不同的主题，那么如果你希望，对于某一个段落，所有的文字都来自同一个主题，你需要对LDA这个模型进行怎么样的修改呢？</p>
</div>
                        </div>
                        <div>
                            <div style="float: left">
                                <a href="096%20%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%E6%9D%A5%E6%A3%80%E6%B5%8B%E5%B9%BF%E5%91%8A%E6%AC%BA%E8%AF%88%EF%BC%9F.md.html">上一页</a>
                            </div>
                            <div style="float: right">
                                <a href="098%20LDA%E5%8F%98%E7%A7%8D%E6%A8%A1%E5%9E%8B%E7%9F%A5%E5%A4%9A%E5%B0%91.md.html">下一页</a>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
            <div class="copyright"><p>© 2019 - 2023 <a href="../../cdn-cgi/l/email-protection.html#7f131313464b4e4e4f483f18121e1613511c1012" target="_blank">Liangliang Lee</a>. Powered by <a href="https://vertx.io/" target="_blank">Vert.x</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p></div>
        </div>

        <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
    </div>
<script data-cfasync="false" src="../../cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/vb26e4fa9e5134444860be286fd8771851679335129114" integrity="sha512-M3hN/6cva/SjwrOtyXeUa5IuCT0sedyfT+jK/OV+s+D0RnzrTfwjwJHhd+wYfMm9HJSrZ1IKksOdddLuN6KOzw==" data-cf-beacon='{"rayId":"7aee64224edf9676","version":"2023.3.0","r":1,"token":"1f5d475227ce4f0089a7cff1ab17c0f5","si":100}' crossorigin="anonymous"></script>
</body>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', 'G-NPSEEVD756');
    var path = window.location.pathname
    var cookie = getCookie("lastPath");
    console.log(path)
    if (path.replace("/", "") === "") {
        if (cookie.replace("/", "") !== "") {
            console.log(cookie)
            document.getElementById("tip").innerHTML = "<a href='" + cookie + "'>跳转到上次进度</a>"
        }
    } else {
        setCookie("lastPath", path)
    }

    function setCookie(cname, cvalue) {
        var d = new Date();
        d.setTime(d.getTime() + (180 * 24 * 60 * 60 * 1000));
        var expires = "expires=" + d.toGMTString();
        document.cookie = cname + "=" + cvalue + "; " + expires + ";path = /";
    }

    function getCookie(cname) {
        var name = cname + "=";
        var ca = document.cookie.split(';');
        for (var i = 0; i < ca.length; i++) {
            var c = ca[i].trim();
            if (c.indexOf(name) === 0) return c.substring(name.length, c.length);
        }
        return "";
    }

    hljs.initHighlightingOnLoad()

</script>

</html>
