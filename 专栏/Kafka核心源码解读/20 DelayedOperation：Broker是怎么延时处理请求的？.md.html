<!DOCTYPE html>
<!-- saved from url=(0046)https://kaiiiz.github.io/hexo-theme-book-demo/ -->
<html xmlns="http://www.w3.org/1999/xhtml">

<head>

    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
        <link rel="icon" href="../../static/favicon.png">
        <title>20 DelayedOperation：Broker是怎么延时处理请求的？.md</title>
        <!-- Spectre.css framework -->
        <link rel="stylesheet" href="../../static/index.css">
        <link rel="stylesheet"
              href="../../static/highlight.min.css">
        <script src="../../static/highlight.min.js"></script>
        <!-- theme css & js -->
        <meta name="generator" content="Hexo 4.2.0">
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5295275829820252"
                crossorigin="anonymous"></script>
        <script async defer data-website-id="83e5d5db-9d06-40e3-b780-cbae722fdf8c" src="https://analyze.lianglianglee.com/umami.js"></script>
    </head>

<body>

    <div class="book-container">
        <div class="book-sidebar">
            <div class="book-brand">
                <a href="../../index.html">
                    <img src="../../static/favicon.png">
                    <span>技术文章摘抄</span>
                </a>
            </div>
            <div class="book-menu uncollapsible">
                <ul class="uncollapsible">
                    <li><a href="../../index.html" class="current-tab">首页</a></li>
                </ul>

                <ul class="uncollapsible">
                    <li><a href="../index.html">上一级</a></li>
                </ul>

                <ul class="uncollapsible">
                    <li>

                        
                        <a href="00%20%E5%AF%BC%E8%AF%BB%20%E6%9E%84%E5%BB%BAKafka%E5%B7%A5%E7%A8%8B%E5%92%8C%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83%E3%80%81Scala%E8%AF%AD%E8%A8%80%E7%83%AD%E8%BA%AB.md.html">00 导读 构建Kafka工程和源码阅读环境、Scala语言热身.md</a>

                    </li>
                    <li>

                        
                        <a href="00%20%E5%BC%80%E7%AF%87%E8%AF%8D%20%20%E9%98%85%E8%AF%BB%E6%BA%90%E7%A0%81%EF%BC%8C%E9%80%90%E6%B8%90%E6%88%90%E4%BA%86%E8%81%8C%E4%B8%9A%E8%BF%9B%E9%98%B6%E9%81%93%E8%B7%AF%E4%B8%8A%E7%9A%84%E2%80%9C%E5%BF%85%E9%80%89%E9%A1%B9%E2%80%9D.md.html">00 开篇词  阅读源码，逐渐成了职业进阶道路上的“必选项”.md</a>

                    </li>
                    <li>

                        
                        <a href="00%20%E9%87%8D%E7%A3%85%E5%8A%A0%E9%A4%90%20%E5%B8%A6%E4%BD%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8Scala%E8%AF%AD%E8%A8%80.md.html">00 重磅加餐 带你快速入门Scala语言.md</a>

                    </li>
                    <li>

                        
                        <a href="01%20%E6%97%A5%E5%BF%97%E6%AE%B5%EF%BC%9A%E4%BF%9D%E5%AD%98%E6%B6%88%E6%81%AF%E6%96%87%E4%BB%B6%E7%9A%84%E5%AF%B9%E8%B1%A1%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F.md.html">01 日志段：保存消息文件的对象是怎么实现的？.md</a>

                    </li>
                    <li>

                        
                        <a href="02%20%E6%97%A5%E5%BF%97%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E6%97%A5%E5%BF%97%E7%A9%B6%E7%AB%9F%E6%98%AF%E5%A6%82%E4%BD%95%E5%8A%A0%E8%BD%BD%E6%97%A5%E5%BF%97%E6%AE%B5%E7%9A%84%EF%BC%9F.md.html">02 日志（上）：日志究竟是如何加载日志段的？.md</a>

                    </li>
                    <li>

                        
                        <a href="03%20%E6%97%A5%E5%BF%97%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82Log%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C.md.html">03 日志（下）：彻底搞懂Log对象的常见操作.md</a>

                    </li>
                    <li>

                        
                        <a href="04%20%E7%B4%A2%E5%BC%95%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E6%94%B9%E8%BF%9B%E7%9A%84%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E5%9C%A8Kafka%E7%B4%A2%E5%BC%95%E7%9A%84%E5%BA%94%E7%94%A8.md.html">04 索引（上）：改进的二分查找算法在Kafka索引的应用.md</a>

                    </li>
                    <li>

                        
                        <a href="05%20%E7%B4%A2%E5%BC%95%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E4%BD%8D%E7%A7%BB%E7%B4%A2%E5%BC%95%E5%92%8C%E6%97%B6%E9%97%B4%E6%88%B3%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F.md.html">05 索引（下）：位移索引和时间戳索引的区别是什么？.md</a>

                    </li>
                    <li>

                        
                        <a href="06%20%E8%AF%B7%E6%B1%82%E9%80%9A%E9%81%93%EF%BC%9A%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0Kafka%E8%AF%B7%E6%B1%82%E9%98%9F%E5%88%97%EF%BC%9F.md.html">06 请求通道：如何实现Kafka请求队列？.md</a>

                    </li>
                    <li>

                        
                        <a href="07%20SocketServer%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9AKafka%E5%88%B0%E5%BA%95%E6%98%AF%E6%80%8E%E4%B9%88%E5%BA%94%E7%94%A8NIO%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E7%9A%84%EF%BC%9F.md.html">07 SocketServer（上）：Kafka到底是怎么应用NIO实现网络通信的？.md</a>

                    </li>
                    <li>

                        
                        <a href="08%20SocketServer%EF%BC%88%E4%B8%AD%EF%BC%89%EF%BC%9A%E8%AF%B7%E6%B1%82%E8%BF%98%E8%A6%81%E5%8C%BA%E5%88%86%E4%BC%98%E5%85%88%E7%BA%A7%EF%BC%9F.md.html">08 SocketServer（中）：请求还要区分优先级？.md</a>

                    </li>
                    <li>

                        
                        <a href="09%20SocketServer%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E5%85%A8%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.md.html">09 SocketServer（下）：请求处理全流程源码分析.md</a>

                    </li>
                    <li>

                        
                        <a href="10%20KafkaApis%EF%BC%9AKafka%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%BA%90%E7%A0%81%E5%85%A5%E5%8F%A3%EF%BC%8C%E6%B2%A1%E6%9C%89%E4%B9%8B%E4%B8%80.md.html">10 KafkaApis：Kafka最重要的源码入口，没有之一.md</a>

                    </li>
                    <li>

                        
                        <a href="11%20Controller%E5%85%83%E6%95%B0%E6%8D%AE%EF%BC%9AController%E9%83%BD%E4%BF%9D%E5%AD%98%E6%9C%89%E5%93%AA%E4%BA%9B%E4%B8%9C%E8%A5%BF%EF%BC%9F%E6%9C%89%E5%87%A0%E7%A7%8D%E7%8A%B6%E6%80%81%EF%BC%9F.md.html">11 Controller元数据：Controller都保存有哪些东西？有几种状态？.md</a>

                    </li>
                    <li>

                        
                        <a href="12%20ControllerChannelManager%EF%BC%9AController%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E8%AF%B7%E6%B1%82%E5%8F%91%E9%80%81%EF%BC%9F.md.html">12 ControllerChannelManager：Controller如何管理请求发送？.md</a>

                    </li>
                    <li>

                        
                        <a href="13%20ControllerEventManager%EF%BC%9A%E5%8F%98%E8%BA%AB%E5%8D%95%E7%BA%BF%E7%A8%8B%E5%90%8E%E7%9A%84Controller%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E4%BA%8B%E4%BB%B6%EF%BC%9F.md.html">13 ControllerEventManager：变身单线程后的Controller如何处理事件？.md</a>

                    </li>
                    <li>

                        
                        <a href="14%20Controller%E9%80%89%E4%B8%BE%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F.md.html">14 Controller选举是怎么实现的？.md</a>

                    </li>
                    <li>

                        
                        <a href="15%20%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3Controller%E5%9C%A8Kafka%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%EF%BC%9F.md.html">15 如何理解Controller在Kafka集群中的作用？.md</a>

                    </li>
                    <li>

                        
                        <a href="16%20TopicDeletionManager%EF%BC%9A%20Topic%E6%98%AF%E6%80%8E%E4%B9%88%E8%A2%AB%E5%88%A0%E9%99%A4%E7%9A%84%EF%BC%9F.md.html">16 TopicDeletionManager： Topic是怎么被删除的？.md</a>

                    </li>
                    <li>

                        
                        <a href="17%20ReplicaStateMachine%EF%BC%9A%E6%8F%AD%E7%A7%98%E5%89%AF%E6%9C%AC%E7%8A%B6%E6%80%81%E6%9C%BA%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.md.html">17 ReplicaStateMachine：揭秘副本状态机实现原理.md</a>

                    </li>
                    <li>

                        
                        <a href="18%20PartitionStateMachine%EF%BC%9A%E5%88%86%E5%8C%BA%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%EF%BC%9F.md.html">18 PartitionStateMachine：分区状态转换如何实现？.md</a>

                    </li>
                    <li>

                        
                        <a href="19%20TimingWheel%EF%BC%9A%E6%8E%A2%E7%A9%B6Kafka%E5%AE%9A%E6%97%B6%E5%99%A8%E8%83%8C%E5%90%8E%E7%9A%84%E9%AB%98%E6%95%88%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95.md.html">19 TimingWheel：探究Kafka定时器背后的高效时间轮算法.md</a>

                    </li>
                    <li>

                        <a class="current-tab" href="20%20DelayedOperation%EF%BC%9ABroker%E6%98%AF%E6%80%8E%E4%B9%88%E5%BB%B6%E6%97%B6%E5%A4%84%E7%90%86%E8%AF%B7%E6%B1%82%E7%9A%84%EF%BC%9F.md.html">20 DelayedOperation：Broker是怎么延时处理请求的？.md</a>
                        

                    </li>
                    <li>

                        
                        <a href="21%20AbstractFetcherThread%EF%BC%9A%E6%8B%89%E5%8F%96%E6%B6%88%E6%81%AF%E5%88%86%E5%87%A0%E6%AD%A5%EF%BC%9F.md.html">21 AbstractFetcherThread：拉取消息分几步？.md</a>

                    </li>
                    <li>

                        
                        <a href="22%20ReplicaFetcherThread%EF%BC%9AFollower%E5%A6%82%E4%BD%95%E6%8B%89%E5%8F%96Leader%E6%B6%88%E6%81%AF%EF%BC%9F.md.html">22 ReplicaFetcherThread：Follower如何拉取Leader消息？.md</a>

                    </li>
                    <li>

                        
                        <a href="23%20ReplicaManager%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%BF%85%E9%A1%BB%E8%A6%81%E6%8E%8C%E6%8F%A1%E7%9A%84%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E7%B1%BB%E5%AE%9A%E4%B9%89%E5%92%8C%E6%A0%B8%E5%BF%83%E5%AD%97%E6%AE%B5.md.html">23 ReplicaManager（上）：必须要掌握的副本管理类定义和核心字段.md</a>

                    </li>
                    <li>

                        
                        <a href="24%20ReplicaManager%EF%BC%88%E4%B8%AD%EF%BC%89%EF%BC%9A%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E8%AF%BB%E5%86%99%E5%89%AF%E6%9C%AC%E7%9A%84%EF%BC%9F.md.html">24 ReplicaManager（中）：副本管理器是如何读写副本的？.md</a>

                    </li>
                    <li>

                        
                        <a href="25%20ReplicaManager%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E5%89%AF%E6%9C%AC%E7%9A%84%EF%BC%9F.md.html">25 ReplicaManager（下）：副本管理器是如何管理副本的？.md</a>

                    </li>
                    <li>

                        
                        <a href="26%20MetadataCache%EF%BC%9ABroker%E6%98%AF%E6%80%8E%E4%B9%88%E5%BC%82%E6%AD%A5%E6%9B%B4%E6%96%B0%E5%85%83%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98%E7%9A%84%EF%BC%9F.md.html">26 MetadataCache：Broker是怎么异步更新元数据缓存的？.md</a>

                    </li>
                    <li>

                        
                        <a href="27%20%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%85%83%E6%95%B0%E6%8D%AE%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E5%85%83%E6%95%B0%E6%8D%AE%EF%BC%9F.md.html">27 消费者组元数据（上）：消费者组都有哪些元数据？.md</a>

                    </li>
                    <li>

                        
                        <a href="28%20%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%85%83%E6%95%B0%E6%8D%AE%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9AKafka%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E8%BF%99%E4%BA%9B%E5%85%83%E6%95%B0%E6%8D%AE%EF%BC%9F.md.html">28 消费者组元数据（下）：Kafka如何管理这些元数据？.md</a>

                    </li>
                    <li>

                        
                        <a href="29%20GroupMetadataManager%EF%BC%9A%E7%BB%84%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%99%A8%E6%98%AF%E4%B8%AA%E4%BB%80%E4%B9%88%E4%B8%9C%E8%A5%BF%EF%BC%9F.md.html">29 GroupMetadataManager：组元数据管理器是个什么东西？.md</a>

                    </li>
                    <li>

                        
                        <a href="30%20GroupMetadataManager%EF%BC%9A%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98%E4%BF%9D%E5%AD%98%E7%9A%84%E5%8F%AA%E6%98%AF%E4%BD%8D%E7%A7%BB%E5%90%97%EF%BC%9F.md.html">30 GroupMetadataManager：位移主题保存的只是位移吗？.md</a>

                    </li>
                    <li>

                        
                        <a href="31%20GroupMetadataManager%EF%BC%9A%E6%9F%A5%E8%AF%A2%E4%BD%8D%E7%A7%BB%E6%97%B6%EF%BC%8C%E4%B8%8D%E7%94%A8%E8%AF%BB%E5%8F%96%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98%EF%BC%9F.md.html">31 GroupMetadataManager：查询位移时，不用读取位移主题？.md</a>

                    </li>
                    <li>

                        
                        <a href="32%20GroupCoordinator%EF%BC%9A%E5%9C%A8Rebalance%E4%B8%AD%EF%BC%8CCoordinator%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E6%88%90%E5%91%98%E5%85%A5%E7%BB%84%EF%BC%9F.md.html">32 GroupCoordinator：在Rebalance中，Coordinator如何处理成员入组？.md</a>

                    </li>
                    <li>

                        
                        <a href="33%20GroupCoordinator%EF%BC%9A%E5%9C%A8Rebalance%E4%B8%AD%EF%BC%8C%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E7%BB%84%E5%90%8C%E6%AD%A5%EF%BC%9F.md.html">33 GroupCoordinator：在Rebalance中，如何进行组同步？.md</a>

                    </li>
                    <li>

                        
                        <a href="%E7%89%B9%E5%88%AB%E6%94%BE%E9%80%81%EF%BC%88%E4%B8%80%EF%BC%89%E7%BB%8F%E5%85%B8%E7%9A%84Kafka%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F.md.html">特别放送（一）经典的Kafka学习资料有哪些？.md</a>

                    </li>
                    <li>

                        
                        <a href="%E7%89%B9%E5%88%AB%E6%94%BE%E9%80%81%EF%BC%88%E4%B8%89%EF%BC%89%E6%88%91%E6%98%AF%E6%80%8E%E4%B9%88%E5%BA%A6%E8%BF%87%E6%97%A5%E5%B8%B8%E4%B8%80%E5%A4%A9%E7%9A%84%EF%BC%9F.md.html">特别放送（三）我是怎么度过日常一天的？.md</a>

                    </li>
                    <li>

                        
                        <a href="%E7%89%B9%E5%88%AB%E6%94%BE%E9%80%81%EF%BC%88%E4%BA%8C%EF%BC%89%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0%E5%B8%A6%E4%BD%A0%E4%BA%86%E8%A7%A3%E5%8F%82%E4%B8%8E%E5%BC%80%E6%BA%90%E7%A4%BE%E5%8C%BA%E7%9A%84%E5%85%A8%E9%83%A8%E6%B5%81%E7%A8%8B.md.html">特别放送（二）一篇文章带你了解参与开源社区的全部流程.md</a>

                    </li>
                    <li>

                        
                        <a href="%E7%89%B9%E5%88%AB%E6%94%BE%E9%80%81%EF%BC%88%E4%BA%94%EF%BC%89%20Kafka%20%E7%A4%BE%E5%8C%BA%E7%9A%84%E9%87%8D%E7%A3%85%E5%8A%9F%E8%83%BD%EF%BC%9A%E7%A7%BB%E9%99%A4%20ZooKeeper%20%E4%BE%9D%E8%B5%96.md.html">特别放送（五） Kafka 社区的重磅功能：移除 ZooKeeper 依赖.md</a>

                    </li>
                    <li>

                        
                        <a href="%E7%89%B9%E5%88%AB%E6%94%BE%E9%80%81%EF%BC%88%E5%9B%9B%EF%BC%8920%E9%81%93%E7%BB%8F%E5%85%B8%E7%9A%84Kafka%E9%9D%A2%E8%AF%95%E9%A2%98%E8%AF%A6%E8%A7%A3.md.html">特别放送（四）20道经典的Kafka面试题详解.md</a>

                    </li>
                    <li>

                        
                        <a href="%E7%BB%93%E6%9D%9F%E8%AF%AD%20%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%8C%E6%88%91%E4%BB%AC%E6%89%8D%E5%88%9A%E4%B8%8A%E8%B7%AF%E5%91%A2.md.html">结束语 源码学习，我们才刚上路呢.md</a>

                    </li>
                </ul>

            </div>
        </div>

        <div class="sidebar-toggle" onclick="sidebar_toggle()" onmouseover="add_inner()" onmouseleave="remove_inner()">
            <div class="sidebar-toggle-inner"></div>
        </div>

        <script>
            function add_inner() {
                let inner = document.querySelector('.sidebar-toggle-inner')
                inner.classList.add('show')
            }

            function remove_inner() {
                let inner = document.querySelector('.sidebar-toggle-inner')
                inner.classList.remove('show')
            }

            function sidebar_toggle() {
                let sidebar_toggle = document.querySelector('.sidebar-toggle')
                let sidebar = document.querySelector('.book-sidebar')
                let content = document.querySelector('.off-canvas-content')
                if (sidebar_toggle.classList.contains('extend')) { // show
                    sidebar_toggle.classList.remove('extend')
                    sidebar.classList.remove('hide')
                    content.classList.remove('extend')
                } else { // hide
                    sidebar_toggle.classList.add('extend')
                    sidebar.classList.add('hide')
                    content.classList.add('extend')
                }
            }


            function open_sidebar() {
                let sidebar = document.querySelector('.book-sidebar')
                let overlay = document.querySelector('.off-canvas-overlay')
                sidebar.classList.add('show')
                overlay.classList.add('show')
            }
            function hide_canvas() {
                let sidebar = document.querySelector('.book-sidebar')
                let overlay = document.querySelector('.off-canvas-overlay')
                sidebar.classList.remove('show')
                overlay.classList.remove('show')
            }

        </script>

        <div class="off-canvas-content">
            <div class="columns">
                <div class="column col-12 col-lg-12">
                    <div class="book-navbar">
                        <!-- For Responsive Layout -->
                        <header class="navbar">
                            <section class="navbar-section">
                                <a onclick="open_sidebar()">
                                    <i class="icon icon-menu"></i>
                                </a>
                            </section>
                        </header>
                    </div>
                    <div class="book-content" style="max-width: 960px; margin: 0 auto;
    overflow-x: auto;
    overflow-y: hidden;">
                        <div class="book-post">
                            <p id="tip" align="center"></p>
                            <div><h1>20 DelayedOperation：Broker是怎么延时处理请求的？</h1>
<p>你好，我是胡夕。</p>
<p>上节课，我们学习了分层时间轮在Kafka中的实现。既然是分层时间轮，那就说明，源码中构造的时间轮是有多个层次的。每一层所表示的总时长，等于该层Bucket数乘以每个Bucket涵盖的时间范围。另外，该总时长自动成为下一层单个Bucket所覆盖的时间范围。</p>
<p>举个例子，目前，Kafka第1层的时间轮固定时长是20毫秒（interval），即有20个Bucket（wheelSize），每个Bucket涵盖1毫秒（tickMs）的时间范围。第2层的总时长是400毫秒，同样有20个Bucket，每个Bucket 20毫秒。依次类推，那么第3层的时间轮时长就是8秒，因为这一层单个Bucket的时长是400毫秒，共有20个Bucket。</p>
<p>基于这种设计，每个延迟请求需要根据自己的超时时间，来决定它要被保存于哪一层时间轮上。我们假设在t=0时创建了第1层的时间轮，那么，该层第1个Bucket保存的延迟请求就是介于[0，1）之间，第2个Bucket保存的是介于[1，2)之间的请求。现在，如果有两个延迟请求，超时时刻分别在18.5毫秒和123毫秒，那么，第1个请求就应该被保存在第1层的第19个Bucket（序号从1开始）中，而第2个请求，则应该被保存在第2层时间轮的第6个Bucket中。</p>
<p>这基本上就是Kafka中分层时间轮的实现原理。Kafka不断向前推动各个层级的时间轮的时钟，按照时间轮的滴答时长，陆续接触到Bucket下的各个延迟任务，从而实现了对请求的延迟处理。</p>
<p>但是，如果你仔细查看的话，就会发现，到目前为止，这套分层时间轮代码和Kafka概念并无直接的关联，比如分层时间轮里并不涉及主题、分区、副本这样的概念，也没有和Controller、副本管理器等Kafka组件进行直接交互。但实际上，延迟处理请求是Kafka的重要功能之一。你可能会问，到底是Kafka的哪部分源码负责创建和维护这套分层时间轮，并将它集成到整体框架中去的呢？答案就是接下来要介绍的两个类：Timer和SystemTimer。</p>
<h2>Timer接口及SystemTimer</h2>
<p>这两个类的源码位于utils.timer包下的Timer.scala文件。其中，<strong>Timer接口定义了管理延迟操作的方法，而SystemTimer是实现延迟操作的关键代码</strong>。后续在学习延迟请求类DelayedOperation时，我们就会发现，调用分层时间轮上的各类操作，都是通过SystemTimer类完成的。</p>
<h3>Timer接口</h3>
<p>接下来，我们就看下它们的源码。首先是Time接口类，代码如下：</p>
<pre><code>trait Timer {
  // 将给定的定时任务插入到时间轮上，等待后续延迟执行
  def add(timerTask: TimerTask): Unit
  // 向前推进时钟，执行已达过期时间的延迟任务
  def advanceClock(timeoutMs: Long): Boolean
  // 获取时间轮上总的定时任务数
  def size: Int
  // 关闭定时器
  def shutdown(): Unit
}
</code></pre>
<p>该Timer接口定义了4个方法。</p>
<ul>
<li>add方法：将给定的定时任务插入到时间轮上，等待后续延迟执行。</li>
<li>advanceClock方法：向前推进时钟，执行已达过期时间的延迟任务。</li>
<li>size方法：获取当前总定时任务数。</li>
<li>shutdown方法：关闭该定时器。</li>
</ul>
<p>其中，最重要的两个方法是<strong>add</strong>和<strong>advanceClock</strong>，它们是<strong>完成延迟请求处理的关键步骤</strong>。接下来，我们结合Timer实现类SystemTimer的源码，重点分析这两个方法。</p>
<h3>SystemTimer类</h3>
<p>SystemTimer类是Timer接口的实现类。它是一个定时器类，封装了分层时间轮对象，为Purgatory提供延迟请求管理功能。所谓的Purgatory，就是保存延迟请求的缓冲区。也就是说，它保存的是因为不满足条件而无法完成，但是又没有超时的请求。</p>
<p>下面，我们从定义和方法两个维度来学习SystemTimer类。</p>
<h4>定义</h4>
<p>首先是该类的定义，代码如下：</p>
<pre><code>class SystemTimer(executorName: String,
                  tickMs: Long = 1,
                  wheelSize: Int = 20,
                  startMs: Long = Time.SYSTEM.hiResClockMs) extends Timer {
  // 单线程的线程池用于异步执行定时任务
  private[this] val taskExecutor = Executors.newFixedThreadPool(1,
    (runnable: Runnable) =&gt; KafkaThread.nonDaemon(&quot;executor-&quot; + executorName, runnable))
  // 延迟队列保存所有Bucket，即所有TimerTaskList对象
  private[this] val delayQueue = new DelayQueue[TimerTaskList]()
  // 总定时任务数
  private[this] val taskCounter = new AtomicInteger(0)
  // 时间轮对象
  private[this] val timingWheel = new TimingWheel(
    tickMs = tickMs,
    wheelSize = wheelSize,
    startMs = startMs,
    taskCounter = taskCounter,
    delayQueue
  )
  // 维护线程安全的读写锁
  private[this] val readWriteLock = new ReentrantReadWriteLock()
  private[this] val readLock = readWriteLock.readLock()
  private[this] val writeLock = readWriteLock.writeLock()
  ......
}
</code></pre>
<p>每个SystemTimer类定义了4个原生字段，分别是executorName、tickMs、wheelSize和startMs。</p>
<p>tickMs和wheelSize是构建分层时间轮的基础，你一定要重点掌握。不过上节课我已经讲过了，而且我在开篇还用具体数字带你回顾了它们的用途，这里就不重复了。另外两个参数不太重要，你只需要知道它们的含义就行了。</p>
<ul>
<li>executorName：Purgatory的名字。Kafka中存在不同的Purgatory，比如专门处理生产者延迟请求的Produce缓冲区、处理消费者延迟请求的Fetch缓冲区等。这里的Produce和Fetch就是executorName。</li>
<li>startMs：该SystemTimer定时器启动时间，单位是毫秒。</li>
</ul>
<p>除了原生字段，SystemTimer类还定义了其他一些字段属性。我介绍3个比较重要的。这3个字段与时间轮都是强相关的。</p>
<ol>
<li><strong>delayQueue字段</strong>。它保存了该定时器下管理的所有Bucket对象。因为是DelayQueue，所以只有在Bucket过期后，才能从该队列中获取到。SystemTimer类的advanceClock方法正是依靠了这个特性向前驱动时钟。关于这一点，一会儿我们详细说。</li>
<li><strong>timingWheel</strong>。TimingWheel是实现分层时间轮的类。SystemTimer类依靠它来操作分层时间轮。</li>
<li><strong>taskExecutor</strong>。它是单线程的线程池，用于异步执行提交的定时任务逻辑。</li>
</ol>
<h4>方法</h4>
<p>说完了类定义与字段，我们看下SystemTimer类的方法。</p>
<p>该类总共定义了6个方法：add、addTimerTaskEntry、reinsert、advanceClock、size和shutdown。</p>
<p>其中，size方法计算的是给定Purgatory下的总延迟请求数，shutdown方法则是关闭前面说到的线程池，而addTimerTaskEntry方法则是将给定的TimerTaskEntry插入到时间轮中。如果该TimerTaskEntry表征的定时任务没有过期或被取消，方法还会将已经过期的定时任务提交给线程池，等待异步执行该定时任务。至于reinsert方法，它会调用addTimerTaskEntry重新将定时任务插入回时间轮。</p>
<p>其实，SystemTimer类最重要的方法是add和advanceClock方法，因为<strong>它们是真正对外提供服务的</strong>。我们先说add方法。add方法的作用，是将给定的定时任务插入到时间轮中进行管理。代码如下：</p>
<pre><code>def add(timerTask: TimerTask): Unit = {
  // 获取读锁。在没有线程持有写锁的前提下，
  // 多个线程能够同时向时间轮添加定时任务
  readLock.lock()
  try {
    // 调用addTimerTaskEntry执行插入逻辑
    addTimerTaskEntry(new TimerTaskEntry(timerTask, timerTask.delayMs + Time.SYSTEM.hiResClockMs))
  } finally {
    // 释放读锁
    readLock.unlock()
  }
}
</code></pre>
<p>add方法就是调用addTimerTaskEntry方法执行插入动作。以下是addTimerTaskEntry的方法代码：</p>
<pre><code>private def addTimerTaskEntry(timerTaskEntry: TimerTaskEntry): Unit = {
  // 视timerTaskEntry状态决定执行什么逻辑：
  // 1. 未过期未取消：添加到时间轮
  // 2. 已取消：什么都不做
  // 3. 已过期：提交到线程池，等待执行
  if (!timingWheel.add(timerTaskEntry)) {
    // 定时任务未取消，说明定时任务已过期
    // 否则timingWheel.add方法应该返回True
    if (!timerTaskEntry.cancelled)
      taskExecutor.submit(timerTaskEntry.timerTask)
  }
}
</code></pre>
<p>TimingWheel的add方法会在定时任务已取消或已过期时，返回False，否则，该方法会将定时任务添加到时间轮，然后返回True。因此，addTimerTaskEntry方法到底执行什么逻辑，取决于给定定时任务的状态：</p>
<ol>
<li>如果该任务既未取消也未过期，那么，addTimerTaskEntry方法将其添加到时间轮；</li>
<li>如果该任务已取消，则该方法什么都不做，直接返回；</li>
<li>如果该任务已经过期，则提交到相应的线程池，等待后续执行。</li>
</ol>
<p>另一个关键方法是advanceClock方法。顾名思义，它的作用是<strong>驱动时钟向前推进</strong>。我们看下代码：</p>
<pre><code>def advanceClock(timeoutMs: Long): Boolean = {
  // 获取delayQueue中下一个已过期的Bucket
  var bucket = delayQueue.poll(
    timeoutMs, TimeUnit.MILLISECONDS)
  if (bucket != null) {
    // 获取写锁
    // 一旦有线程持有写锁，其他任何线程执行add或advanceClock方法时会阻塞
    writeLock.lock()
    try {
      while (bucket != null) {
        // 推动时间轮向前&quot;滚动&quot;到Bucket的过期时间点
        timingWheel.advanceClock(bucket.getExpiration())
        // 将该Bucket下的所有定时任务重写回到时间轮
        bucket.flush(reinsert)
        // 读取下一个Bucket对象
        bucket = delayQueue.poll()
      }
    } finally {
      // 释放写锁
      writeLock.unlock()
    }
    true
  } else {
    false
  }
}
</code></pre>
<p>由于代码逻辑比较复杂，我再画一张图来展示一下：</p>
<p><img src="assets/310c9160f701082ceb90984a7dcfe089.jpg" alt="" /></p>
<p>advanceClock方法要做的事情，就是遍历delayQueue中的所有Bucket，并将时间轮的时钟依次推进到它们的过期时间点，令它们过期。然后，再将这些Bucket下的所有定时任务全部重新插入回时间轮。</p>
<p>我用一张图来说明这个重新插入过程。</p>
<p><img src="assets/535e18ad9516c90ff58baae8cfc9b9ef.png" alt="" /></p>
<p>从这张图中，我们可以看到，在T0时刻，任务①存放在Level 0的时间轮上，而任务②和③存放在Level 1的时间轮上。此时，时钟推进到Level 0的第0个Bucket上，以及Level 1的第0个Bucket上。</p>
<p>当时间来到T19时刻，时钟也被推进到Level 0的第19个Bucket，任务①会被执行。但是，由于一层时间轮是20个Bucket，因此，T19时刻Level 0的时间轮尚未完整走完一圈，此时，Level 1的时间轮状态没有发生任何变化。</p>
<p>当T20时刻到达时，Level 0的时间轮已经执行完成，Level 1的时间轮执行了一次滴答，向前推进一格。此时，Kafka需要将任务②和③插入到Level 0的时间轮上，位置是第20个和第21个Bucket。这个将高层时间轮上的任务插入到低层时间轮的过程，是由advanceClock中的reinsert方法完成。</p>
<p>至于为什么要重新插入回低层次的时间轮，其实是因为，随着时钟的推进，当前时间逐渐逼近任务②和③的超时时间点。它们之间差值的缩小，足以让它们被放入到下一层的时间轮中。</p>
<p>总的来说，SystemTimer类实现了Timer接口的方法，<strong>它封装了底层的分层时间轮，为上层调用方提供了便捷的方法来操作时间轮</strong>。那么，它的上层调用方是谁呢？答案就是DelayedOperationPurgatory类。这就是我们建模Purgatory的地方。</p>
<p>不过，在了解DelayedOperationPurgatory之前，我们要先学习另一个重要的类：DelayedOperation。前者是一个泛型类，它的类型参数恰恰就是DelayedOperation。因此，我们不可能在不了解DelayedOperation的情况下，很好地掌握DelayedOperationPurgatory。</p>
<h2>DelayedOperation类</h2>
<p>这个类位于server包下的DelayedOperation.scala文件中。它是所有Kafka延迟请求类的抽象父类。我们依然从定义和方法这两个维度去剖析它。</p>
<h3>定义</h3>
<p>首先来看定义。代码如下：</p>
<pre><code>abstract class DelayedOperation(override val delayMs: Long,
                                lockOpt: Option[Lock] = None)
  extends TimerTask with Logging {
  // 标识该延迟操作是否已经完成
  private val completed = new AtomicBoolean(false)
  // 防止多个线程同时检查操作是否可完成时发生锁竞争导致操作最终超时
  private val tryCompletePending = new AtomicBoolean(false)
  private[server] val lock: Lock = lockOpt.getOrElse(new ReentrantLock)
  ......
}
</code></pre>
<p>DelayedOperation类是一个抽象类，它的构造函数中只需要传入一个超时时间即可。这个超时时间通常是<strong>客户端发出请求的超时时间</strong>，也就是客户端参数<strong>request.timeout.ms</strong>的值。这个类实现了上节课学到的TimerTask接口，因此，作为一个建模延迟操作的类，它自动继承了TimerTask接口的cancel方法，支持延迟操作的取消，以及TimerTaskEntry的Getter和Setter方法，支持将延迟操作绑定到时间轮相应Bucket下的某个链表元素上。</p>
<p>除此之外，DelayedOperation类额外定义了两个字段：<strong>completed</strong>和<strong>tryCompletePending</strong>。</p>
<p>前者理解起来比较容易，它就是<strong>表征这个延迟操作是否完成的布尔变量</strong>。我重点解释一下tryCompletePending的作用。</p>
<p>这个参数是在1.1版本引入的。在此之前，只有completed参数。但是，这样就可能存在这样一个问题：当多个线程同时检查某个延迟操作是否满足完成条件时，如果其中一个线程持有了锁（也就是上面的lock字段），然后执行条件检查，会发现不满足完成条件。而与此同时，另一个线程执行检查时却发现条件满足了，但是这个线程又没有拿到锁，此时，该延迟操作将永远不会有再次被检查的机会，会导致最终超时。</p>
<p>加入tryCompletePending字段目的，就是<strong>确保拿到锁的线程有机会再次检查条件是否已经满足</strong>。具体是怎么实现的呢？下面讲到maybeTryComplete方法时，我会再带你进行深入的分析。</p>
<p>关于DelayedOperation类的定义，你掌握到这个程度就可以了，重点是学习这些字段是如何在方法中发挥作用的。</p>
<h3>方法</h3>
<p>DelayedOperation类有7个方法。我先介绍下它们的作用，这样你在读源码时就可以心中有数。</p>
<ul>
<li>forceComplete：强制完成延迟操作，不管它是否满足完成条件。每当操作满足完成条件或已经过期了，就需要调用该方法完成该操作。</li>
<li>isCompleted：检查延迟操作是否已经完成。源码使用这个方法来决定后续如何处理该操作。比如如果操作已经完成了，那么通常需要取消该操作。</li>
<li>onExpiration：强制完成之后执行的过期逻辑回调方法。只有真正完成操作的那个线程才有资格调用这个方法。</li>
<li>onComplete：完成延迟操作所需的处理逻辑。这个方法只会在forceComplete方法中被调用。</li>
<li>tryComplete：尝试完成延迟操作的顶层方法，内部会调用forceComplete方法。</li>
<li>maybeTryComplete：线程安全版本的tryComplete方法。这个方法其实是社区后来才加入的，不过已经慢慢地取代了tryComplete，现在外部代码调用的都是这个方法了。</li>
<li>run：调用延迟操作超时后的过期逻辑，也就是组合调用forceComplete + onExpiration。</li>
</ul>
<p>我们说过，DelayedOperation是抽象类，对于不同类型的延时请求，onExpiration、onComplete和tryComplete的处理逻辑也各不相同，因此需要子类来实现它们。</p>
<p>其他方法的代码大多短小精悍，你一看就能明白，我就不做过多解释了。我重点说下maybeTryComplete方法。毕竟，这是社区为了规避因多线程访问产生锁争用导致线程阻塞，从而引发请求超时问题而做的努力。先看方法代码：</p>
<pre><code>private[server] def maybeTryComplete(): Boolean = {
  var retry = false  // 是否需要重试
  var done = false   // 延迟操作是否已完成
  do {
    if (lock.tryLock()) {   // 尝试获取锁对象
      try {
        tryCompletePending.set(false)
        done = tryComplete()
      } finally {
        lock.unlock()
      }
      // 运行到这里的线程持有锁，其他线程只能运行else分支的代码
      // 如果其他线程将maybeTryComplete设置为true，那么retry=true
      // 这就相当于其他线程给了本线程重试的机会
      retry = tryCompletePending.get()
    } else {
      // 运行到这里的线程没有拿到锁
      // 设置tryCompletePending=true给持有锁的线程一个重试的机会
      retry = !tryCompletePending.getAndSet(true)
    }
  } while (!isCompleted &amp;&amp; retry)
  done
}
</code></pre>
<p>为了方便你理解，我画了一张流程图说明它的逻辑：</p>
<p><img src="assets/35bd69c5aa46d52a358976152508daa3.jpg" alt="" /></p>
<p>从图中可以看出，这个方法可能会被多个线程同时访问，只是不同线程会走不同的代码分支，分叉点就在<strong>尝试获取锁的if语句</strong>。</p>
<p>如果拿到锁对象，就依次执行清空tryCompletePending状态、完成延迟请求、释放锁以及读取最新retry状态的动作。未拿到锁的线程，就只能设置tryCompletePending状态，来间接影响retry值，从而给获取到锁的线程一个重试的机会。这里的重试，是通过do…while循环的方式实现的。</p>
<p>好了，DelayedOperation类我们就说到这里。除了这些公共方法，你最好结合一两个具体子类的方法实现，体会下具体延迟请求类是如何实现tryComplete方法的。我推荐你从DelayedProduce类的<strong>tryComplete方法</strong>开始。</p>
<p>我们之前总说，acks=all的PRODUCE请求很容易成为延迟请求，因为它必须等待所有的ISR副本全部同步消息之后才能完成，你可以顺着这个思路，研究下DelayedProduce的tryComplete方法是如何实现的。</p>
<h2>DelayedOperationPurgatory类</h2>
<p>接下来，我们补上延迟请求模块的最后一块“拼图”：DelayedOperationPurgatory类的源码分析。</p>
<p>该类是实现Purgatory的地方。从代码结构上看，它是一个Scala伴生对象。也就是说，源码文件同时定义了DelayedOperationPurgatory Object和Class。Object中仅仅定义了apply工厂方法和一个名为Shards的字段，这个字段是DelayedOperationPurgatory监控列表的数组长度信息。因此，我们还是重点学习DelayedOperationPurgatory Class的源码。</p>
<p>前面说过，DelayedOperationPurgatory类是一个泛型类，它的参数类型是DelayedOperation的具体子类。因此，通常情况下，每一类延迟请求都对应于一个DelayedOperationPurgatory实例。这些实例一般都保存在上层的管理器中。比如，与消费者组相关的心跳请求、加入组请求的Purgatory实例，就保存在GroupCoordinator组件中，而与生产者相关的PRODUCE请求的Purgatory实例，被保存在分区对象或副本状态机中。</p>
<h3>定义</h3>
<p>至于怎么学，还是老规矩，我们先从定义开始。代码如下：</p>
<pre><code>final class DelayedOperationPurgatory[T &lt;: DelayedOperation](
  purgatoryName: String, 
  timeoutTimer: Timer, 
  brokerId: Int = 0, 
  purgeInterval: Int = 1000, 
  reaperEnabled: Boolean = true, 
  timerEnabled: Boolean = true) extends Logging with KafkaMetricsGroup {
  ......
}
</code></pre>
<p>定义中有6个字段。其中，很多字段都有默认参数，比如，最后两个参数分别表示是否启动删除线程，以及是否启用分层时间轮。现在，源码中所有类型的Purgatory实例都是默认启动的，因此无需特别留意它们。</p>
<p>purgeInterval这个参数用于控制删除线程移除Bucket中的过期延迟请求的频率，在绝大部分情况下，都是1秒一次。当然，对于生产者、消费者以及删除消息的AdminClient而言，Kafka分别定义了专属的参数允许你调整这个频率。比如，生产者参数producer.purgatory.purge.interval.requests，就是做这个用的。</p>
<p>事实上，需要传入的参数一般只有两个：<strong>purgatoryName</strong>和<strong>brokerId</strong>，它们分别表示这个Purgatory的名字和Broker的序号。</p>
<p>而timeoutTimer，就是我们前面讲过的SystemTimer实例，我就不重复解释了。</p>
<h3>Wathcers和WatcherList</h3>
<p>DelayedOperationPurgatory还定义了两个内置类，分别是Watchers和WatcherList。</p>
<p><strong>Watchers是基于Key的一个延迟请求的监控链表</strong>。它的主体代码如下：</p>
<pre><code>private class Watchers(val key: Any) {
  private[this] val operations = 
    new ConcurrentLinkedQueue[T]()
  // 其他方法......
}
</code></pre>
<p>每个Watchers实例都定义了一个延迟请求链表，而这里的Key可以是任何类型，比如表示消费者组的字符串类型、表示主题分区的TopicPartitionOperationKey类型。你不用穷尽这里所有的Key类型，你只需要了解，Watchers是一个通用的延迟请求链表，就行了。Kafka利用它来<strong>监控保存其中的延迟请求的可完成状态</strong>。</p>
<p>既然Watchers主要的数据结构是链表，那么，它的所有方法本质上就是一个链表操作。比如，tryCompleteWatched方法会遍历整个链表，并尝试完成其中的延迟请求。再比如，cancel方法也是遍历链表，再取消掉里面的延迟请求。至于watch方法，则是将延迟请求加入到链表中。</p>
<p>说完了Watchers，我们看下WatcherList类。它非常短小精悍，完整代码如下：</p>
<pre><code>private class WatcherList {
  // 定义一组按照Key分组的Watchers对象
  val watchersByKey = new Pool[Any, Watchers](Some((key: Any) =&gt; new Watchers(key)))
  val watchersLock = new ReentrantLock()
  // 返回所有Watchers对象
  def allWatchers = {
    watchersByKey.values
  }
}
</code></pre>
<p>WatcherList最重要的字段是<strong>watchersByKey</strong>。它是一个Pool，Pool就是Kafka定义的池对象，它本质上就是一个ConcurrentHashMap。watchersByKey的Key可以是任何类型，而Value就是Key对应类型的一组Watchers对象。</p>
<p>说完了DelayedOperationPurgatory类的两个内部类Watchers和WatcherList，我们可以开始学习该类的两个重要方法：tryCompleteElseWatch和checkAndComplete方法。</p>
<p>前者的作用是<strong>检查操作是否能够完成</strong>，如果不能的话，就把它加入到对应Key所在的WatcherList中。以下是方法代码：</p>
<pre><code>def tryCompleteElseWatch(operation: T, watchKeys: Seq[Any]): Boolean = {
  assert(watchKeys.nonEmpty, &quot;The watch key list can't be empty&quot;)
  var isCompletedByMe = operation.tryComplete()
  // 如果该延迟请求是由本线程完成的，直接返回true即可
  if (isCompletedByMe)
    return true
  var watchCreated = false
  // 遍历所有要监控的Key
  for(key &lt;- watchKeys) {
    // 再次查看请求的完成状态，如果已经完成，就说明是被其他线程完成的，返回false
    if (operation.isCompleted)
      return false
    // 否则，将该operation加入到Key所在的WatcherList
    watchForOperation(key, operation)
    // 设置watchCreated标记，表明该任务已经被加入到WatcherList
    if (!watchCreated) {
      watchCreated = true
      // 更新Purgatory中总请求数
      estimatedTotalOperations.incrementAndGet()
    }
  }
  // 再次尝试完成该延迟请求
  isCompletedByMe = operation.maybeTryComplete()
  if (isCompletedByMe)
    return true
  // 如果依然不能完成此请求，将其加入到过期队列
  if (!operation.isCompleted) {
    if (timerEnabled)
      timeoutTimer.add(operation)
    if (operation.isCompleted) {
      operation.cancel()
    }
  }
  false
}
</code></pre>
<p>该方法的名字折射出了它要做的事情：先尝试完成请求，如果无法完成，则把它加入到WatcherList中进行监控。具体来说，tryCompleteElseWatch调用tryComplete方法，尝试完成延迟请求，如果返回结果是true，就说明执行tryCompleteElseWatch方法的线程正常地完成了该延迟请求，也就不需要再添加到WatcherList了，直接返回true就行了。</p>
<p>否则的话，代码会遍历所有要监控的Key，再次查看请求的完成状态。如果已经完成，就说明是被其他线程完成的，返回false；如果依然无法完成，则将该请求加入到Key所在的WatcherList中，等待后续完成。同时，设置watchCreated标记，表明该任务已经被加入到WatcherList以及更新Purgatory中总请求数。</p>
<p>待遍历完所有Key之后，源码会再次尝试完成该延迟请求，如果完成了，就返回true，否则就取消该请求，然后将其加入到过期队列，最后返回false。</p>
<p>总的来看，你要掌握这个方法要做的两个事情：</p>
<ol>
<li>先尝试完成延迟请求；</li>
<li>如果不行，就加入到WatcherList，等待后面再试。</li>
</ol>
<p>那么，代码是在哪里进行重试的呢？这就需要用到第2个方法checkAndComplete了。</p>
<p>该方法会<strong>检查给定Key所在的WatcherList中的延迟请求是否满足完成条件</strong>，如果是的话，则结束掉它们。我们一起看下源码：</p>
<pre><code>def checkAndComplete(key: Any): Int = {
  // 获取给定Key的WatcherList
  val wl = watcherList(key)
  // 获取WatcherList中Key对应的Watchers对象实例
  val watchers = inLock(wl.watchersLock) { wl.watchersByKey.get(key) }
  // 尝试完成满足完成条件的延迟请求并返回成功完成的请求数
  val numCompleted = if (watchers == null)
    0
  else
    watchers.tryCompleteWatched()
  debug(s&quot;Request key $key unblocked $numCompleted $purgatoryName operations&quot;)
  numCompleted
}
</code></pre>
<p>代码很简单，就是根据给定Key，获取对应的WatcherList对象，以及它下面保存的Watchers对象实例，然后尝试完成满足完成条件的延迟请求，并返回成功完成的请求数。</p>
<p>可见，非常重要的步骤就是<strong>调用Watchers的tryCompleteWatched方法，去尝试完成那些已满足完成条件的延迟请求</strong>。</p>
<h2>总结</h2>
<p>今天，我们重点学习了分层时间轮的上层组件，包括Timer接口及其实现类SystemTimer、DelayedOperation类以及DelayedOperationPurgatory类。你基本上可以认为，它们是逐级被调用的关系，即<strong>DelayedOperation调用SystemTimer类，DelayedOperationPurgatory管理DelayedOperation</strong>。它们共同实现了Broker端对于延迟请求的处理，基本思想就是，<strong>能立即完成的请求马上完成，否则就放入到名为Purgatory的缓冲区中</strong>。后续，DelayedOperationPurgatory类的方法会自动地处理这些延迟请求。</p>
<p>我们来回顾一下重点。</p>
<ul>
<li>SystemTimer类：Kafka定义的定时器类，封装了底层分层时间轮，实现了时间轮Bucket的管理以及时钟向前推进功能。它是实现延迟请求后续被自动处理的基础。</li>
<li>DelayedOperation类：延迟请求的高阶抽象类，提供了完成请求以及请求完成和过期后的回调逻辑实现。</li>
<li>DelayedOperationPurgatory类：Purgatory实现类，该类定义了WatcherList对象以及对WatcherList的操作方法，而WatcherList是实现延迟请求后续自动处理的关键数据结构。</li>
</ul>
<p>总的来说，延迟请求模块属于Kafka的冷门组件。毕竟，大部分的请求还是能够被立即处理的。了解这部分模块的最大意义在于，你可以学习Kafka这个分布式系统是如何异步循环操作和管理定时任务的。这个功能是所有分布式系统都要面临的课题，因此，弄明白了这部分的原理和代码实现，后续我们在自行设计类似的功能模块时，就非常容易了。</p>
<h2>课后讨论</h2>
<p>DelayedOperationPurgatory类中定义了一个Reaper线程，用于将已过期的延迟请求从数据结构中移除掉。这实际上是由DelayedOperationPurgatory的advanceClock方法完成的。它里面有这样一句：</p>
<pre><code>val purged = watcherLists.foldLeft(0) {
  case (sum, watcherList) =&gt; sum + watcherList.allWatchers.map(_.purgeCompleted()).sum
}
</code></pre>
<p>你觉得这个语句是做什么用的？</p>
<p>欢迎在留言区写下你的思考和答案，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p>
</div>
                        </div>
                        <div>
                            <div style="float: left">
                                <a href="19%20TimingWheel%EF%BC%9A%E6%8E%A2%E7%A9%B6Kafka%E5%AE%9A%E6%97%B6%E5%99%A8%E8%83%8C%E5%90%8E%E7%9A%84%E9%AB%98%E6%95%88%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95.md.html">上一页</a>
                            </div>
                            <div style="float: right">
                                <a href="21%20AbstractFetcherThread%EF%BC%9A%E6%8B%89%E5%8F%96%E6%B6%88%E6%81%AF%E5%88%86%E5%87%A0%E6%AD%A5%EF%BC%9F.md.html">下一页</a>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
            <div class="copyright"><p>© 2019 - 2023 <a href="../../cdn-cgi/l/email-protection.html#e28e8e8edbd6d3d3d2d5a2858f838b8ecc818d8f" target="_blank">Liangliang Lee</a>. Powered by <a href="https://vertx.io/" target="_blank">Vert.x</a> and <a href="https://github.com/kaiiiz/hexo-theme-book" target="_blank">hexo-theme-book</a>.</p></div>
        </div>

        <a class="off-canvas-overlay" onclick="hide_canvas()"></a>
    </div>
<script data-cfasync="false" src="../../cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/vb26e4fa9e5134444860be286fd8771851679335129114" integrity="sha512-M3hN/6cva/SjwrOtyXeUa5IuCT0sedyfT+jK/OV+s+D0RnzrTfwjwJHhd+wYfMm9HJSrZ1IKksOdddLuN6KOzw==" data-cf-beacon='{"rayId":"7aef2fe6ede3641c","version":"2023.3.0","r":1,"token":"1f5d475227ce4f0089a7cff1ab17c0f5","si":100}' crossorigin="anonymous"></script>
</body>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NPSEEVD756"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', 'G-NPSEEVD756');
    var path = window.location.pathname
    var cookie = getCookie("lastPath");
    console.log(path)
    if (path.replace("/", "") === "") {
        if (cookie.replace("/", "") !== "") {
            console.log(cookie)
            document.getElementById("tip").innerHTML = "<a href='" + cookie + "'>跳转到上次进度</a>"
        }
    } else {
        setCookie("lastPath", path)
    }

    function setCookie(cname, cvalue) {
        var d = new Date();
        d.setTime(d.getTime() + (180 * 24 * 60 * 60 * 1000));
        var expires = "expires=" + d.toGMTString();
        document.cookie = cname + "=" + cvalue + "; " + expires + ";path = /";
    }

    function getCookie(cname) {
        var name = cname + "=";
        var ca = document.cookie.split(';');
        for (var i = 0; i < ca.length; i++) {
            var c = ca[i].trim();
            if (c.indexOf(name) === 0) return c.substring(name.length, c.length);
        }
        return "";
    }

    hljs.initHighlightingOnLoad()

</script>

</html>
